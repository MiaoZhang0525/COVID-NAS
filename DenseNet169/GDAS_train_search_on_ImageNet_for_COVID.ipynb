{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils_imagenet\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model_search import Network\n",
    "from architect import Architect\n",
    "\n",
    "\n",
    "import genotypes\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "#import albumentations as albu\n",
    "#from albumentations.pytorch import ToTensor\n",
    "#from catalyst.data import Augmentor\n",
    "#import torchxrayvision as xrv\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "#from catalyst.data import Augmentor\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"imagenet\")\n",
    "parser.add_argument('--data', type=str, default='/home/jiahzhao/Data/imagenet', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.025, help='init learning rate')\n",
    "parser.add_argument('--learning_rate_min', type=float, default=0.001, help='min learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=50, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=8, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=8, help='total number of layers')\n",
    "parser.add_argument('--model_path', type=str, default='saved_models', help='path to save the model')\n",
    "parser.add_argument('--cutout', action='store_true', default=False, help='use cutout')\n",
    "parser.add_argument('--cutout_length', type=int, default=16, help='cutout length')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0.3, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='EXP', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=100, help='random seed')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "parser.add_argument('--train_portion', type=float, default=0.5, help='portion of training data')\n",
    "parser.add_argument('--unrolled', action='store_true', default=True, help='use one-step unrolled validation loss')\n",
    "parser.add_argument('--arch_learning_rate', type=float, default=3e-4, help='learning rate for arch encoding')\n",
    "parser.add_argument('--arch_weight_decay', type=float, default=1e-3, help='weight decay for arch encoding')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "CIFAR_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "model = Network(args.init_channels, CIFAR_CLASSES, args.layers, criterion)\n",
    "model = model.cuda()\n",
    "logging.info(\"param size = %fMB\", utils_imagenet.count_parameters_in_MB(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "      model.parameters(),\n",
    "      args.learning_rate,\n",
    "      momentum=args.momentum,\n",
    "      weight_decay=args.weight_decay)\n",
    "\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "validdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_data = dset.ImageFolder(\n",
    "traindir,\n",
    "transforms.Compose([\n",
    "  transforms.RandomResizedCrop(224),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ColorJitter(\n",
    "    brightness=0.4,\n",
    "    contrast=0.4,\n",
    "    saturation=0.4,\n",
    "    hue=0.2),\n",
    "  transforms.ToTensor(),\n",
    "  normalize,\n",
    "]))\n",
    "\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(args.train_portion * num_train))\n",
    "split = int(np.floor(0.001 * num_train))\n",
    "split2 = int(np.floor(0.002 * num_train))\n",
    "\n",
    "\n",
    "\n",
    "train_queue = torch.utils.data.DataLoader(\n",
    "      train_data, batch_size=args.batch_size,\n",
    "      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
    "      pin_memory=True, num_workers=2)\n",
    "\n",
    "valid_queue = torch.utils.data.DataLoader(\n",
    "      train_data, batch_size=args.batch_size,\n",
    "      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:split2]),\n",
    "      pin_memory=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "116\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "batchsize=10\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainset = CovidCTDataset(root_dir='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Images-processed',\n",
    "                          txt_COVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/COVID/trainCT_COVID.txt',\n",
    "                          txt_NonCOVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                          transform= train_transformer)\n",
    "valset = CovidCTDataset(root_dir='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Images-processed',\n",
    "                          txt_COVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/COVID/valCT_COVID.txt',\n",
    "                          txt_NonCOVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "testset = CovidCTDataset(root_dir='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Images-processed',\n",
    "                          txt_COVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/COVID/testCT_COVID.txt',\n",
    "                          txt_NonCOVID='/data/jiahzhao/COVID-CT-master_SEARCH_ON_cifar/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "print(testset.__len__())\n",
    "\n",
    "batchsize=2\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=True, shuffle=True,pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(valset, batch_size=batchsize, drop_last=True, shuffle=False,pin_memory=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, drop_last=True, shuffle=False,pin_memory=True, num_workers=2)\n",
    "\n",
    "##we use the validation performance on COVID dataset after transfering on training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "\n",
    "alpha = None\n",
    "device = 'cuda'\n",
    "\n",
    "model_covid = Network(args.init_channels, 2, args.layers, criterion)\n",
    "model_covid = model_covid.cuda()\n",
    "model_covid.to(device)\n",
    "\n",
    "\n",
    "def tranfer_weights(model,model_covid):\n",
    "    model_covid = torch.nn.DataParallel(model_covid)   \n",
    "    model = torch.nn.DataParallel(model)\n",
    "    newmodel_dict=model_covid.state_dict()\n",
    "    premodel_dict=model.state_dict()\n",
    "    new_list=list(newmodel_dict.keys())\n",
    "    pre_list=list(premodel_dict.keys())\n",
    "    for i in range(4184):####The model contains 4186 keys, we need exclude the last layer\n",
    "        newmodel_dict[new_list[i]]=premodel_dict[pre_list[i]]\n",
    "    \n",
    "    model_covid.load_state_dict(newmodel_dict)\n",
    "\n",
    "    model_covid=model_covid.module\n",
    "    return model_covid\n",
    "\n",
    "model_covid=tranfer_weights(model,model_covid)\n",
    "\n",
    "\n",
    "#dict_name=list(model.state_dict())\n",
    "#for i,p in enumerate(dict_name):\n",
    "    #print(i,p)\n",
    "\n",
    "architect = Architect(model_covid, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_covid = optim.Adam(model_covid.parameters(), lr=0.0001)\n",
    "\n",
    "def train_covid(train_loader, model_covid, criterion, optimizer):\n",
    "    objs = utils_imagenet.AvgrageMeter()\n",
    "    top1 = utils_imagenet.AvgrageMeter()\n",
    "    model_covid.train()\n",
    "    \n",
    "    loss = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    for step, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        input, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "     \n",
    "        target = target.cuda(async=True)\n",
    "        input = input.cuda()\n",
    "        input = Variable(input)\n",
    "        target = Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits= model_covid(input)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "def get_weights_from_arch(arch_comb):\n",
    "    k = sum(1 for i in range(model._steps) for n in range(2+i))\n",
    "    num_ops = len(genotypes.PRIMITIVES)\n",
    "    n_nodes = model._steps\n",
    "\n",
    "    alphas_normal = Variable(torch.zeros(k, num_ops).cuda(), requires_grad=False)\n",
    "    alphas_reduce = Variable(torch.zeros(k, num_ops).cuda(), requires_grad=False)\n",
    "\n",
    "    offset = 0\n",
    "    for i in range(n_nodes):\n",
    "        normal1 = np.int_(arch_comb[0][2*i])\n",
    "        normal2 = np.int_(arch_comb[0][2*i+1])\n",
    "        reduce1 = np.int_(arch_comb[1][2*i])\n",
    "        reduce2 = np.int_(arch_comb[1][2*i+1])\n",
    "        alphas_normal[offset+normal1[1],normal1[0]] = 1\n",
    "        alphas_normal[offset+normal2[1],normal2[0]] = 1\n",
    "        alphas_reduce[offset+reduce1[1],reduce1[0]] = 1\n",
    "        alphas_reduce[offset+reduce2[1],reduce2[0]] = 1\n",
    "        offset += (i+2)\n",
    "\n",
    "    model_weights = [\n",
    "      alphas_normal,\n",
    "      alphas_reduce,\n",
    "    ]\n",
    "    return model_weights\n",
    "\n",
    "\n",
    "def set_model_weights(model, weights):\n",
    "    model.alphas_normal = weights[0]\n",
    "    model.alphas_reduce = weights[1]\n",
    "    model._arch_parameters = [model.alphas_normal, model.alphas_reduce]\n",
    "\n",
    "from genotypes import PRIMITIVES\n",
    "def _parse_gene(weights):\n",
    "    gene = []\n",
    "    n = 2\n",
    "    start = 0\n",
    "    for i in range(4):\n",
    "        end = start + n\n",
    "        W = weights[start:end].copy()\n",
    "        edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "        for j in edges:\n",
    "            k_best = None\n",
    "            for k in range(len(W[j])):\n",
    "                if k != PRIMITIVES.index('none'):\n",
    "                    if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                        k_best = k\n",
    "            gene.append((k_best, j))\n",
    "        start = end\n",
    "        n += 1\n",
    "    return gene\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def train(train_queue, valid_queue, model,model_covid, architect, criterion, optimizer, lr):\n",
    "    objs = utils_imagenet.AvgrageMeter()\n",
    "    top1 = utils_imagenet.AvgrageMeter()\n",
    "    top5 = utils_imagenet.AvgrageMeter()\n",
    "\n",
    "    for step, (input, target) in enumerate(train_queue):\n",
    "        model.train()\n",
    "        n = input.size(0)\n",
    "\n",
    "        input = Variable(input, requires_grad=False).cuda()\n",
    "        target = Variable(target, requires_grad=False).cuda(async=True)\n",
    "\n",
    "        # get a random minibatch from the search queue with replacement\n",
    "        batch_next = next(iter(val_loader))\n",
    "        input_search, target_search = batch_next['img'].to(device), batch_next['label'].to(device)\n",
    "\n",
    "        input_search = Variable(input_search, requires_grad=False).cuda()\n",
    "        target_search = Variable(target_search, requires_grad=False).cuda(async=True)\n",
    "        \n",
    "        train_covid(train_loader, model_covid, criterion, optimizer_covid)######train on covid\n",
    "\n",
    "        architect.step(input, target, input_search, target_search, lr, optimizer, unrolled=False)\n",
    "\n",
    "        arch_param_save=model_covid.arch_parameters()\n",
    "    \n",
    "        #temp= opt.initial_temp * np.exp(-opt.anneal_rate * step)\n",
    "        temp= 2.5* np.exp(-0.00003  * step)\n",
    "        temperature=torch.tensor([temp]).type(torch.FloatTensor)\n",
    "        \n",
    "        alpha_nor=torch.tensor(arch_param_save[0]).type(torch.FloatTensor)\n",
    "        \n",
    "        while True:\n",
    "            gumbels = -torch.empty_like(alpha_nor).exponential_().log()\n",
    "            logits  = (alpha_nor.log_softmax(dim=1) + gumbels) / temp\n",
    "            probs   = nn.functional.softmax(logits, dim=1)\n",
    "            index   = probs.max(-1, keepdim=True)[1]\n",
    "            one_h   = torch.zeros_like(logits).scatter_(-1, index, 1.0)\n",
    "            hardwts = one_h - probs.detach() + probs\n",
    "            if (torch.isinf(gumbels).any()) or (torch.isinf(probs).any()) or (torch.isnan(probs).any()):\n",
    "                continue\n",
    "            else: break\n",
    "        gene_normal = _parse_gene(F.softmax(probs, dim=-1).data.cpu().numpy())    \n",
    "        \n",
    "        alpha_red=torch.tensor(arch_param_save[1]).type(torch.FloatTensor)        \n",
    "        while True:\n",
    "            gumbels = -torch.empty_like(alpha_red).exponential_().log()\n",
    "            logits  = (alpha_nor.log_softmax(dim=1) + gumbels) / temp\n",
    "            probs   = nn.functional.softmax(logits, dim=1)\n",
    "            index   = probs.max(-1, keepdim=True)[1]\n",
    "            one_h   = torch.zeros_like(logits).scatter_(-1, index, 1.0)\n",
    "            hardwts = one_h - probs.detach() + probs\n",
    "            if (torch.isinf(gumbels).any()) or (torch.isinf(probs).any()) or (torch.isnan(probs).any()):\n",
    "                continue\n",
    "            else: break        \n",
    "        \n",
    "        gene_reduce = _parse_gene(F.softmax(probs, dim=-1).data.cpu().numpy())\n",
    "        \n",
    "        arch_gene = [gene_normal,gene_reduce]\n",
    "        model_weights=get_weights_from_arch(arch_gene)        \n",
    "        set_model_weights(model,model_weights)      \n",
    "        logits = model(input)        \n",
    "        loss_cur=criterion(logits, target) \n",
    "\n",
    "\n",
    "        loss=loss_cur\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        objs.update(loss.data, n)\n",
    "\n",
    "        \n",
    "        set_model_weights(model,arch_param_save)###########################set back\n",
    "\n",
    "\n",
    "    return objs.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1248, 0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1253],\n",
      "        [0.1251, 0.1249, 0.1250, 0.1249, 0.1248, 0.1251, 0.1251, 0.1251],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1251, 0.1251],\n",
      "        [0.1252, 0.1250, 0.1251, 0.1250, 0.1248, 0.1249, 0.1248, 0.1252],\n",
      "        [0.1249, 0.1252, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],\n",
      "        [0.1248, 0.1250, 0.1249, 0.1252, 0.1250, 0.1252, 0.1249, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1249, 0.1248, 0.1250, 0.1251, 0.1251, 0.1250],\n",
      "        [0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1248, 0.1252],\n",
      "        [0.1251, 0.1248, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251, 0.1251],\n",
      "        [0.1250, 0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1250, 0.1252],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1251, 0.1249, 0.1250, 0.1249, 0.1251, 0.1249],\n",
      "        [0.1252, 0.1250, 0.1249, 0.1251, 0.1251, 0.1248, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1250, 0.1250, 0.1252, 0.1248, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1249, 0.1251, 0.1251, 0.1250, 0.1250, 0.1250, 0.1250, 0.1248],\n",
      "        [0.1250, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1249, 0.1248],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1252, 0.1250],\n",
      "        [0.1248, 0.1251, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251],\n",
      "        [0.1248, 0.1249, 0.1251, 0.1249, 0.1250, 0.1252, 0.1250, 0.1251],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1248],\n",
      "        [0.1249, 0.1249, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1252],\n",
      "        [0.1248, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1252],\n",
      "        [0.1250, 0.1251, 0.1249, 0.1250, 0.1249, 0.1252, 0.1248, 0.1251],\n",
      "        [0.1251, 0.1251, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1247, 0.1251, 0.1248, 0.1252, 0.1251, 0.1251, 0.1248],\n",
      "        [0.1248, 0.1247, 0.1249, 0.1252, 0.1250, 0.1252, 0.1250, 0.1252],\n",
      "        [0.1247, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1249, 0.1251],\n",
      "        [0.1249, 0.1248, 0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/data/jiahzhao/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-72c772ac8a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_covid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchitect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ace17287c1b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_queue, valid_queue, model, model_covid, architect, criterion, optimizer, lr)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mtarget_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtrain_covid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_covid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_covid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m######train on covid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0marchitect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munrolled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ace17287c1b>\u001b[0m in \u001b[0;36mtrain_covid\u001b[0;34m(train_loader, model_covid, criterion, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jiahzhao/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jiahzhao/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "\n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    logging.info('epoch %d lr %e', epoch, lr)\n",
    "\n",
    "    genotype = model.genotype()\n",
    "    logging.info('genotype = %s', genotype)\n",
    "\n",
    "    print(F.softmax(model.alphas_normal, dim=-1))\n",
    "    print(F.softmax(model.alphas_reduce, dim=-1))\n",
    "\n",
    "    # training\n",
    "    train_obj = train(train_queue, val_loader, model,model_covid, architect, criterion, optimizer, lr)\n",
    "    \n",
    "    \n",
    "    targetlist, scorelist, predlist=infer(val_loader, model, criterion,epoch)\n",
    "    \n",
    "    print(model.genotype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
