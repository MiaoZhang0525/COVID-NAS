{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import utils_imagenet\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import genotypes\n",
    "import torch.utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model import NetworkImageNet as Network\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"imagenet\")\n",
    "parser.add_argument('--data', type=str, default='../data/imagenet/', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.1, help='init learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-5, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=100, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=250, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=48, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=14, help='total number of layers')\n",
    "parser.add_argument('--auxiliary', action='store_true', default=True, help='use auxiliary tower')\n",
    "parser.add_argument('--auxiliary_weight', type=float, default=0.4, help='weight for auxiliary loss')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='EXP', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "parser.add_argument('--arch', type=str, default='DARTS', help='which architecture to use')\n",
    "parser.add_argument('--grad_clip', type=float, default=5., help='gradient clipping')\n",
    "parser.add_argument('--label_smooth', type=float, default=0.1, help='label smoothing')\n",
    "parser.add_argument('--gamma', type=float, default=0.97, help='learning rate decay')\n",
    "parser.add_argument('--decay_period', type=int, default=1, help='epochs between two learning rate decays')\n",
    "parser.add_argument('--parallel', action='store_true', default=False, help='data parallelism')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "logging.info('gpu device = %d' % args.gpu)\n",
    "logging.info(\"args = %s\", args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 48\n",
      "48 192 48\n",
      "192 192 48\n",
      "192 192 48\n",
      "192 192 96\n",
      "192 384 96\n",
      "384 384 96\n",
      "384 384 96\n",
      "384 384 96\n",
      "384 384 192\n",
      "384 768 192\n",
      "768 768 192\n",
      "768 768 192\n",
      "768 768 192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genotype = eval(\"genotypes.%s\" % args.arch)\n",
    "pre_model = Network(args.init_channels, CLASSES, args.layers, args.auxiliary, genotype)\n",
    "pre_model = pre_model.cuda()\n",
    "#pre_model.load_state_dict(torch.load('model_best.pth.tar')['state_dict'])\n",
    "\n",
    "pre_model.load_state_dict(torch.load('DARTS_imagenet_model.pt',map_location='cuda:0')['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/taoliu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from catalyst.data import Augmentor\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "from catalyst.data import Augmentor\n",
    "from skimage.io import imread, imsave\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "batchsize=10\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "116\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "trainset = CovidCTDataset(root_dir='/tmp/mozilla_taoliu0/COVID-CT-master/Images-processed',\n",
    "                          txt_COVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/COVID/trainCT_COVID.txt',\n",
    "                          txt_NonCOVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                          transform= train_transformer)\n",
    "valset = CovidCTDataset(root_dir='/tmp/mozilla_taoliu0/COVID-CT-master/Images-processed',\n",
    "                          txt_COVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/COVID/valCT_COVID.txt',\n",
    "                          txt_NonCOVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "testset = CovidCTDataset(root_dir='/tmp/mozilla_taoliu0/COVID-CT-master/Images-processed',\n",
    "                          txt_COVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/COVID/testCT_COVID.txt',\n",
    "                          txt_NonCOVID='/tmp/mozilla_taoliu0/COVID-CT-master/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "print(testset.__len__())\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True,pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False,pin_memory=True, num_workers=4)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False,pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "device = 'cuda'\n",
    "\n",
    "# In[152]:\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            data = data[:, 0, :, :]\n",
    "            data = data[:, None, :, :]\n",
    "            data = data.repeat(1,3,1,1)\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "# #             # FN    predict 0 label 1\n",
    "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "# #             # FP    predict 1 label 0\n",
    "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'DARTS_Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 48\n",
      "48 192 48\n",
      "192 192 48\n",
      "192 192 48\n",
      "192 192 96\n",
      "192 384 96\n",
      "384 384 96\n",
      "384 384 96\n",
      "384 384 96\n",
      "384 384 192\n",
      "384 768 192\n",
      "768 768 192\n",
      "768 768 192\n",
      "768 768 192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): NetworkImageNet(\n",
       "    (stem0): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (stem1): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (cells): ModuleList(\n",
       "      (0): Cell(\n",
       "        (preprocess0): FactorizedReduce(\n",
       "          (relu): ReLU()\n",
       "          (conv_1): Conv2d(48, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (conv_2): Conv2d(48, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (6): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=48, bias=False)\n",
       "              (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (2): Identity()\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Cell(\n",
       "        (preprocess0): FactorizedReduce(\n",
       "          (relu): ReLU()\n",
       "          (conv_1): Conv2d(192, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (conv_2): Conv2d(192, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=96, bias=False)\n",
       "              (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (2): Identity()\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Cell(\n",
       "        (preprocess0): FactorizedReduce(\n",
       "          (relu): ReLU()\n",
       "          (conv_1): Conv2d(384, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (conv_2): Conv2d(384, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Cell(\n",
       "        (preprocess0): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (preprocess1): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (_ops): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): SepConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (4): ReLU()\n",
       "              (5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (6): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Identity()\n",
       "          (6): Identity()\n",
       "          (7): DilConv(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=192, bias=False)\n",
       "              (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (auxiliary_head): AuxiliaryHeadImageNet(\n",
       "      (features): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 768, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        (6): ReLU(inplace=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "    (global_pooling): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(args.init_channels, 2, args.layers, args.auxiliary, genotype)\n",
    "model = torch.nn.DataParallel(model)\n",
    "new_model = model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_dict=torch.load('model_best.pth.tar')\n",
    "pre_model = torch.nn.DataParallel(pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel_dict=model.state_dict()\n",
    "premodel_dict=pre_model.state_dict()\n",
    "new_list=list(newmodel_dict.keys())\n",
    "pre_list=list(premodel_dict.keys())\n",
    "for i in range(952):####The model contains 956 keys, we need exclude the last layer\n",
    "    newmodel_dict[new_list[i]]=premodel_dict[pre_list[i]]\n",
    "\n",
    "model.load_state_dict(newmodel_dict)\n",
    "\n",
    "model=model.module\n",
    "#dict_name=list(model.state_dict())\n",
    "#for i,p in enumerate(dict_name):\n",
    "#    print(i,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    objs = utils_imagenet.AvgrageMeter()\n",
    "    top1 = utils_imagenet.AvgrageMeter()\n",
    "    model.train()\n",
    "    \n",
    "    loss = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    for step, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        input, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        input = input[:, 0, :, :]\n",
    "        input = input[:, None, :, :]\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target.long(), alpha, use_cuda=True)\n",
    "        input = input.repeat(1,3,1,1)        \n",
    "        \n",
    "        \n",
    "        target = target.cuda(async=True)\n",
    "        input = input.cuda()\n",
    "        input = Variable(input)\n",
    "        target = Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, logits_aux = model(input)\n",
    "        loss = criterion(logits, target)\n",
    "        if args.auxiliary:\n",
    "            loss_aux = criterion(logits_aux, target)\n",
    "            loss += args.auxiliary_weight*loss_aux\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec2 = utils_imagenet.accuracy(logits, target, topk=(1,2))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1.data, n)\n",
    "       # top2.update(prec5.data, n)\n",
    "\n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('train %03d %e %f', step, objs.avg, top1.avg)\n",
    "            \n",
    "\n",
    "\n",
    "        pred = logits.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if step % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, step, len(train_loader),\n",
    "                100.0 * step / len(train_loader), loss.item()/ bs))\n",
    "    \n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "            \n",
    "            \n",
    "\n",
    "    return top1.avg, objs.avg    \n",
    "    \n",
    "    \n",
    "def infer(val_loader, model, criterion,epoch):\n",
    "    \n",
    "    objs = utils_imagenet.AvgrageMeter()\n",
    "    top1 = utils_imagenet.AvgrageMeter()\n",
    "    top5 = utils_imagenet.AvgrageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        \n",
    "    \n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            data = data[:, 0, :, :]\n",
    "            data = data[:, None, :, :]\n",
    "            data = data.repeat(1,3,1,1)\n",
    "            data = Variable(data, volatile=True).cuda()\n",
    "            target = Variable(target, volatile=True).cuda(async=True)            \n",
    "            \n",
    "            \n",
    "            output, logits_aux = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target)\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "          \n",
    "    return targetlist, scorelist, predlist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, epsilon):\n",
    "        super(CrossEntropyLabelSmooth, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "        targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "        targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "        loss = (-targets * log_probs).mean(0).sum()\n",
    "        return loss\n",
    "    \n",
    "\n",
    "bs = 10\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "#scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 3000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "criterion_smooth = CrossEntropyLabelSmooth(CLASSES, args.label_smooth)\n",
    "criterion_smooth = criterion_smooth.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/43 (0%)]\tTrain Loss: 0.086589\n",
      "Train Epoch: 0 [10/43 (23%)]\tTrain Loss: 0.082616\n",
      "Train Epoch: 0 [20/43 (47%)]\tTrain Loss: 0.079588\n",
      "Train Epoch: 0 [30/43 (70%)]\tTrain Loss: 0.065690\n",
      "Train Epoch: 0 [40/43 (93%)]\tTrain Loss: 0.048338\n",
      "\n",
      "Train set: Average loss: 0.0032, Accuracy: 302/424 (71%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.78265762 0.7553367  0.76479697 0.62797612 0.57338947 0.66108179\n",
      " 0.70876461 0.73932266 0.65130717 0.6504243  0.57405186 0.64098626\n",
      " 0.70083487 0.69505757 0.66451705 0.54386461 0.53634298 0.68464261\n",
      " 0.50072676 0.76579016 0.7734012  0.72113246 0.58321965 0.78650421\n",
      " 0.71059954 0.66066408 0.82955045 0.71571118 0.6917522  0.64622241\n",
      " 0.7171495  0.76633608 0.77965564 0.54974657 0.46087518 0.70157117\n",
      " 0.50830054 0.69637167 0.72912616 0.72024506 0.72182626 0.68261713\n",
      " 0.75177789 0.69148535 0.77922779 0.60383201 0.80093533 0.77097279\n",
      " 0.8035236  0.75489128 0.82391548 0.49534646 0.68615776 0.53868878\n",
      " 0.88136405 0.37183452 0.74671423 0.66473085 0.7784465  0.67055273\n",
      " 0.92110652 0.93017524 0.91376913 0.92433751 0.79590982 0.73902315\n",
      " 0.67642975 0.89306134 0.83886665 0.82870275 0.77864629 0.76490664\n",
      " 0.77141958 0.78272933 0.75673246 0.88565344 0.87841815 0.83618903\n",
      " 0.87653518 0.7831288  0.8064993  0.87844145 0.84572572 0.84159124\n",
      " 0.87141567 0.88782489 0.85552436 0.8808527  0.67151397 0.84022212\n",
      " 0.76101547 0.74838948 0.77276433 0.74792022 0.7735855  0.74677885\n",
      " 0.57957798 0.82297766 0.87285382 0.84329402 0.77556515 0.862571\n",
      " 0.76539791 0.69522852 0.65210277 0.75624895 0.80323577 0.60109931\n",
      " 0.78759789 0.73161161 0.69365227 0.7538358  0.84080619 0.80550539\n",
      " 0.800304   0.86866426]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 0 TN= 60 FN= 56 FP= 0\n",
      "TP+FP 0\n",
      "precision nan\n",
      "recall 0.0\n",
      "F1 nan\n",
      "acc 0.5172413793103449\n",
      "AUCp 0.5\n",
      "AUC 0.8306547619047618\n",
      "\n",
      " The epoch is 0, average recall: 0.0000, average precision: nan,average F1: nan, average accuracy: 0.5172, average AUC: 0.8307\n",
      "Train Epoch: 1 [0/43 (0%)]\tTrain Loss: 0.053890\n",
      "Train Epoch: 1 [10/43 (23%)]\tTrain Loss: 0.046873\n",
      "Train Epoch: 1 [20/43 (47%)]\tTrain Loss: 0.030212\n",
      "Train Epoch: 1 [30/43 (70%)]\tTrain Loss: 0.033898\n",
      "Train Epoch: 1 [40/43 (93%)]\tTrain Loss: 0.068194\n",
      "\n",
      "Train set: Average loss: 0.0011, Accuracy: 347/424 (82%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.06091082e-01 6.61074281e-01 3.20247650e-01 1.19270645e-01\n",
      " 1.32176303e-03 7.25425268e-03 6.79006100e-01 9.17509571e-02\n",
      " 5.50288241e-03 2.28105038e-02 5.99830002e-02 3.11864587e-03\n",
      " 3.69893610e-02 3.53168184e-03 1.19210233e-03 2.86875130e-03\n",
      " 2.83295196e-02 1.94120049e-01 3.82515742e-03 2.28598230e-02\n",
      " 2.91826967e-02 1.66718692e-01 6.02927152e-03 2.67736584e-01\n",
      " 3.30099128e-02 1.42229404e-02 7.17801094e-01 1.71131268e-02\n",
      " 2.03482192e-02 1.91151642e-03 1.47495549e-02 4.15228382e-02\n",
      " 3.06004137e-01 2.49409885e-03 2.78965309e-02 3.90129127e-02\n",
      " 1.43949818e-02 8.57919678e-02 9.02164727e-02 4.86817174e-02\n",
      " 1.48668230e-01 2.86099195e-01 3.23091716e-01 1.21266112e-01\n",
      " 2.13957414e-01 2.59495936e-02 2.90113896e-01 1.35725856e-01\n",
      " 6.33364201e-01 5.07486939e-01 7.05159903e-01 1.26859257e-02\n",
      " 1.81292757e-01 7.44975405e-04 6.67570412e-01 1.61793258e-03\n",
      " 5.88041782e-01 1.87556949e-02 4.13230419e-01 2.81033758e-02\n",
      " 9.44297373e-01 9.46349025e-01 9.74145889e-01 9.74650025e-01\n",
      " 1.53854653e-01 2.97335148e-01 2.01616928e-01 9.65809047e-01\n",
      " 7.70638466e-01 7.62837708e-01 8.66518021e-02 1.49923444e-01\n",
      " 4.91734296e-01 2.47212052e-01 2.78417796e-01 8.64798784e-01\n",
      " 7.87726998e-01 7.28614390e-01 9.02525008e-01 6.68393910e-01\n",
      " 8.74077260e-01 8.84456217e-01 9.28104758e-01 6.72382355e-01\n",
      " 7.68760920e-01 9.59874451e-01 8.72376084e-01 6.57589257e-01\n",
      " 1.77730471e-01 5.25108278e-01 6.86861515e-01 5.44070229e-02\n",
      " 3.12832803e-01 8.32233906e-01 3.32931250e-01 8.36070478e-01\n",
      " 2.41939295e-02 5.00978768e-01 7.90866137e-01 9.62142110e-01\n",
      " 7.72747844e-02 9.47707117e-01 1.52614102e-01 8.25955048e-02\n",
      " 4.18774448e-02 2.02486426e-01 6.53407454e-01 3.52635235e-02\n",
      " 4.79955196e-01 7.62007711e-03 6.99834466e-01 6.71231031e-01\n",
      " 8.62961829e-01 7.84064353e-01 1.81798950e-01 2.22145736e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 2 [0/43 (0%)]\tTrain Loss: 0.019303\n",
      "Train Epoch: 2 [10/43 (23%)]\tTrain Loss: 0.015058\n",
      "Train Epoch: 2 [20/43 (47%)]\tTrain Loss: 0.058374\n",
      "Train Epoch: 2 [30/43 (70%)]\tTrain Loss: 0.095944\n",
      "Train Epoch: 2 [40/43 (93%)]\tTrain Loss: 0.057396\n",
      "\n",
      "Train set: Average loss: 0.0004, Accuracy: 369/424 (87%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.69087174e-03 7.28627503e-01 4.33232665e-01 9.08432230e-02\n",
      " 4.22214973e-04 3.53684532e-03 7.19015419e-01 6.70565665e-02\n",
      " 5.43363858e-03 4.83455025e-02 2.07264334e-01 1.14424492e-03\n",
      " 6.11716509e-02 9.74282331e-04 7.95122818e-04 6.71482878e-04\n",
      " 6.97972998e-03 2.99388051e-01 2.82193720e-02 9.74297747e-02\n",
      " 1.67239830e-01 2.88703412e-01 1.39421597e-02 5.33454835e-01\n",
      " 1.10675544e-01 2.12969892e-02 9.33728218e-01 1.31471634e-01\n",
      " 1.16231486e-01 2.05222354e-03 1.67605191e-01 2.25255698e-01\n",
      " 2.77085543e-01 3.27668199e-03 1.51725169e-02 2.10007876e-02\n",
      " 1.09023424e-02 1.89775035e-01 8.46716315e-02 5.28052710e-02\n",
      " 8.56895447e-02 2.03371927e-01 6.87234640e-01 1.60017714e-01\n",
      " 7.28984714e-01 1.45533141e-02 2.41883367e-01 4.03975472e-02\n",
      " 8.52254152e-01 6.47714019e-01 9.56914604e-01 3.79988030e-02\n",
      " 3.57311040e-01 2.86084577e-03 7.48407722e-01 9.43887886e-03\n",
      " 8.67241621e-01 3.36841196e-02 4.84812826e-01 4.39822078e-02\n",
      " 9.88024294e-01 9.88536596e-01 9.88452137e-01 9.87461627e-01\n",
      " 2.97283322e-01 7.49655187e-01 2.09604472e-01 9.89130855e-01\n",
      " 9.22203660e-01 9.45404291e-01 2.07860067e-01 4.20906156e-01\n",
      " 8.64059627e-01 6.32627904e-01 6.60407662e-01 9.21041846e-01\n",
      " 9.55488265e-01 9.12293673e-01 9.43485856e-01 9.12944317e-01\n",
      " 9.86630321e-01 9.80619431e-01 9.86704707e-01 8.16921532e-01\n",
      " 8.62062871e-01 9.89990115e-01 9.72959876e-01 8.64583969e-01\n",
      " 3.35669100e-01 7.79144704e-01 8.17824781e-01 2.60361016e-01\n",
      " 7.29619861e-01 9.51625466e-01 8.15095067e-01 8.52481425e-01\n",
      " 5.05627654e-02 9.00489688e-01 8.97104621e-01 9.89369154e-01\n",
      " 1.44184738e-01 9.87711132e-01 1.37777865e-01 1.74062490e-01\n",
      " 6.99995905e-02 6.24920726e-01 8.48566115e-01 3.43536884e-01\n",
      " 5.01156330e-01 3.26815188e-01 8.70707095e-01 7.33788252e-01\n",
      " 9.69553530e-01 8.49214673e-01 9.91298333e-02 3.33574891e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/43 (0%)]\tTrain Loss: 0.043385\n",
      "Train Epoch: 3 [10/43 (23%)]\tTrain Loss: 0.041744\n",
      "Train Epoch: 3 [20/43 (47%)]\tTrain Loss: 0.052528\n",
      "Train Epoch: 3 [30/43 (70%)]\tTrain Loss: 0.054613\n",
      "Train Epoch: 3 [40/43 (93%)]\tTrain Loss: 0.029317\n",
      "\n",
      "Train set: Average loss: 0.0004, Accuracy: 388/424 (92%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.80712760e-04 7.06256568e-01 2.17018679e-01 5.20902053e-02\n",
      " 3.79252364e-04 1.77325812e-04 7.35539675e-01 1.21693268e-01\n",
      " 3.23414890e-04 1.50394430e-02 2.31664851e-02 1.68654624e-05\n",
      " 1.21466145e-02 4.22601443e-05 1.41527362e-05 2.57640227e-06\n",
      " 4.01817786e-04 9.74617228e-02 1.84665481e-03 3.79795022e-02\n",
      " 2.34590136e-02 2.21552849e-01 1.83674798e-03 6.54761612e-01\n",
      " 3.68986130e-01 8.69881827e-03 9.64414775e-01 2.30630897e-02\n",
      " 1.53509406e-02 1.10118752e-04 7.47946277e-02 4.22871590e-01\n",
      " 1.61552772e-01 3.88508124e-06 2.76553783e-05 1.40378208e-04\n",
      " 1.68679544e-05 5.54758668e-01 1.98290553e-02 4.86836620e-02\n",
      " 1.61885336e-01 2.92120636e-01 7.31285691e-01 2.53903151e-01\n",
      " 8.38592052e-01 2.19180365e-03 5.51821291e-01 2.71847576e-01\n",
      " 9.72869456e-01 4.00100738e-01 9.87472892e-01 1.20810501e-01\n",
      " 3.26912284e-01 9.50196176e-04 7.88316011e-01 3.92015791e-04\n",
      " 8.98189902e-01 8.16578139e-03 2.61050940e-01 9.22349393e-02\n",
      " 9.98976231e-01 9.98488188e-01 9.99201953e-01 9.98677313e-01\n",
      " 4.22672123e-01 7.50899911e-01 2.24254236e-01 9.95310724e-01\n",
      " 9.65290964e-01 9.73598659e-01 1.62571773e-01 4.83282387e-01\n",
      " 9.15827692e-01 4.60319698e-01 5.35279572e-01 9.68995094e-01\n",
      " 9.80135143e-01 8.95188689e-01 9.73428547e-01 9.94980276e-01\n",
      " 9.98179555e-01 9.97503102e-01 9.98344898e-01 6.84092760e-01\n",
      " 7.07571208e-01 9.96899486e-01 9.95862961e-01 9.68970239e-01\n",
      " 5.49479090e-02 8.93436730e-01 7.16645598e-01 9.44097459e-01\n",
      " 9.00347114e-01 9.57654297e-01 9.31742489e-01 9.24649000e-01\n",
      " 3.67586203e-02 9.84106421e-01 9.61839139e-01 9.98522699e-01\n",
      " 1.76958546e-01 9.95699167e-01 1.15140103e-01 4.86112803e-01\n",
      " 1.67931512e-01 8.76861155e-01 9.65727448e-01 3.86063308e-02\n",
      " 7.63104081e-01 5.16944192e-02 9.65646386e-01 9.83585119e-01\n",
      " 9.90532875e-01 9.27304804e-01 3.90532687e-02 5.84270537e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "Train Epoch: 4 [0/43 (0%)]\tTrain Loss: 0.007375\n",
      "Train Epoch: 4 [10/43 (23%)]\tTrain Loss: 0.017528\n",
      "Train Epoch: 4 [20/43 (47%)]\tTrain Loss: 0.006686\n",
      "Train Epoch: 4 [30/43 (70%)]\tTrain Loss: 0.013793\n",
      "Train Epoch: 4 [40/43 (93%)]\tTrain Loss: 0.013175\n",
      "\n",
      "Train set: Average loss: 0.0003, Accuracy: 400/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.32138911e-03 7.10221291e-01 2.73073196e-01 1.13957554e-01\n",
      " 3.04502348e-04 1.09453138e-03 7.59920537e-01 4.17179056e-02\n",
      " 9.41427134e-04 6.69757603e-03 3.55379190e-03 4.63975266e-05\n",
      " 5.04764542e-03 2.90003536e-05 1.23468481e-05 1.79452206e-06\n",
      " 1.98389567e-03 2.43122101e-01 1.90397361e-04 6.54431467e-04\n",
      " 1.08613633e-03 1.63439233e-02 1.40447301e-05 6.18861139e-01\n",
      " 3.83020658e-03 5.62403759e-04 8.22669923e-01 3.28008085e-04\n",
      " 7.48612219e-05 1.06973926e-06 3.12130363e-03 1.28648607e-02\n",
      " 5.48550077e-02 2.67278983e-06 4.82160867e-05 4.42127566e-05\n",
      " 1.86730667e-05 1.30845457e-01 2.16034031e-03 2.22944887e-03\n",
      " 2.44087516e-03 2.12581083e-02 3.17471147e-01 8.29711184e-03\n",
      " 5.12299955e-01 1.41952455e-03 2.59995848e-01 1.24020753e-02\n",
      " 9.66425955e-01 1.84234291e-01 9.63449597e-01 1.82574484e-02\n",
      " 2.50929948e-02 7.33794950e-05 6.43258333e-01 8.98905000e-06\n",
      " 8.20205867e-01 6.05175854e-04 3.41166675e-01 1.56095158e-03\n",
      " 9.99427080e-01 9.99007404e-01 9.99679685e-01 9.98873293e-01\n",
      " 4.80527356e-02 5.15128374e-01 2.60012448e-01 9.62834597e-01\n",
      " 9.74895477e-01 9.47648466e-01 7.77757615e-02 5.07654369e-01\n",
      " 6.93042219e-01 4.57066119e-01 1.58974379e-01 9.26408410e-01\n",
      " 9.94269133e-01 9.77834463e-01 9.54330504e-01 9.96286511e-01\n",
      " 9.96939898e-01 9.98281479e-01 9.97995138e-01 7.55202651e-01\n",
      " 6.44936025e-01 9.96542394e-01 9.92966175e-01 9.23657954e-01\n",
      " 1.07708909e-02 6.63244188e-01 6.63854003e-01 2.20753551e-01\n",
      " 8.10670078e-01 9.90783334e-01 7.29652226e-01 9.61172044e-01\n",
      " 4.81280079e-03 9.82893646e-01 9.57238138e-01 9.95040715e-01\n",
      " 1.34291813e-01 9.96583700e-01 5.56696542e-02 4.22465444e-01\n",
      " 1.05640069e-01 5.88566780e-01 9.90338743e-01 3.03469431e-02\n",
      " 2.22120836e-01 3.02184913e-02 9.50442374e-01 9.61334109e-01\n",
      " 9.95625973e-01 7.44727254e-01 2.94442335e-03 8.91070515e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 5 [0/43 (0%)]\tTrain Loss: 0.005781\n",
      "Train Epoch: 5 [10/43 (23%)]\tTrain Loss: 0.011642\n",
      "Train Epoch: 5 [20/43 (47%)]\tTrain Loss: 0.007689\n",
      "Train Epoch: 5 [30/43 (70%)]\tTrain Loss: 0.022409\n",
      "Train Epoch: 5 [40/43 (93%)]\tTrain Loss: 0.003706\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 391/424 (92%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.98459836e-06 8.44161987e-01 3.59303385e-01 1.90256163e-01\n",
      " 3.34863726e-05 2.32928563e-04 8.85439456e-01 7.14161098e-02\n",
      " 5.80732885e-04 2.46037473e-03 1.26304431e-02 4.85007986e-05\n",
      " 4.88734469e-02 1.88120443e-03 7.13601821e-06 1.28649458e-06\n",
      " 1.25734406e-02 2.82404065e-01 7.48501741e-04 4.81379814e-02\n",
      " 4.64539463e-03 6.25992790e-02 1.82058924e-04 8.02405596e-01\n",
      " 5.75771779e-02 1.58006381e-02 9.78102028e-01 4.57386160e-03\n",
      " 9.53622628e-03 2.30845271e-05 7.33505888e-03 1.33096844e-01\n",
      " 4.06281166e-02 6.66858032e-05 1.69864460e-03 1.47565838e-03\n",
      " 7.90797276e-05 4.29755718e-01 5.99924102e-02 1.19314380e-01\n",
      " 2.99931496e-01 6.58045769e-01 6.74690723e-01 9.95284021e-02\n",
      " 7.14224398e-01 4.25434858e-03 1.67170331e-01 4.61201835e-03\n",
      " 9.39218462e-01 3.39179724e-01 9.75740194e-01 4.37238673e-03\n",
      " 1.27889723e-01 1.08044542e-05 4.79612082e-01 3.45135481e-06\n",
      " 8.81032109e-01 6.12104021e-04 3.52366418e-01 3.41848400e-03\n",
      " 9.99747097e-01 9.99822438e-01 9.99828219e-01 9.99422193e-01\n",
      " 3.17530990e-01 9.57283437e-01 7.35990107e-01 9.98171687e-01\n",
      " 9.86047745e-01 9.91406798e-01 3.04136306e-01 7.76902854e-01\n",
      " 9.00463223e-01 9.62494671e-01 8.91106844e-01 9.23878789e-01\n",
      " 9.96266901e-01 9.89765584e-01 9.84148502e-01 9.97159958e-01\n",
      " 9.98544812e-01 9.98883784e-01 9.98988330e-01 8.42239857e-01\n",
      " 9.14789498e-01 9.98065174e-01 9.97450054e-01 9.47449505e-01\n",
      " 7.49836981e-01 9.96265829e-01 9.92203236e-01 2.15822026e-01\n",
      " 9.39138830e-01 9.94785845e-01 9.01193440e-01 9.90845382e-01\n",
      " 1.81555387e-03 9.86249268e-01 9.92554367e-01 9.99345481e-01\n",
      " 1.88178405e-01 9.97188270e-01 4.20283735e-01 4.24164057e-01\n",
      " 3.30080576e-02 4.30233181e-01 9.69724417e-01 5.83287850e-02\n",
      " 3.46229225e-01 2.41191918e-03 9.85249579e-01 9.58742976e-01\n",
      " 9.95314956e-01 9.89380360e-01 9.35339808e-01 5.82437932e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/43 (0%)]\tTrain Loss: 0.014738\n",
      "Train Epoch: 6 [10/43 (23%)]\tTrain Loss: 0.012614\n",
      "Train Epoch: 6 [20/43 (47%)]\tTrain Loss: 0.006186\n",
      "Train Epoch: 6 [30/43 (70%)]\tTrain Loss: 0.019828\n",
      "Train Epoch: 6 [40/43 (93%)]\tTrain Loss: 0.007308\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 393/424 (93%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.17300470e-07 7.71291852e-01 8.37918445e-02 1.86515134e-02\n",
      " 3.89926527e-07 9.28920690e-06 8.05240154e-01 2.50798706e-02\n",
      " 8.42418922e-06 3.02599440e-03 1.34313377e-02 1.27021503e-05\n",
      " 4.93727252e-02 2.20066049e-05 8.66608843e-07 8.21408079e-08\n",
      " 6.10814663e-04 1.34872526e-01 2.88707175e-04 3.79175469e-02\n",
      " 5.90248324e-04 1.37366289e-02 1.49584112e-05 6.29170418e-01\n",
      " 1.72699976e-03 4.34872898e-04 9.44391310e-01 7.05146886e-05\n",
      " 8.54831815e-05 7.74168143e-07 1.39879412e-03 5.81813231e-02\n",
      " 5.84068615e-03 1.06383915e-04 1.29115675e-03 3.68817913e-04\n",
      " 3.54318581e-05 2.69589305e-01 1.57090891e-02 5.54094976e-03\n",
      " 1.06324274e-02 2.33172193e-01 4.30808723e-01 6.30820394e-02\n",
      " 8.16757679e-01 1.19914310e-02 1.29892826e-01 2.15492258e-03\n",
      " 9.18590426e-01 5.40615439e-01 9.64904964e-01 8.53550970e-04\n",
      " 4.97048646e-02 1.49392713e-06 7.81656742e-01 8.39036602e-07\n",
      " 7.89929092e-01 1.13088987e-03 1.22482710e-01 3.56215605e-04\n",
      " 9.99632239e-01 9.99801815e-01 9.99812424e-01 9.99495149e-01\n",
      " 1.01116747e-01 7.26132393e-01 6.98992759e-02 9.98003542e-01\n",
      " 9.79366958e-01 9.93597388e-01 1.00287795e-01 4.99989599e-01\n",
      " 7.66033173e-01 9.04110134e-01 5.87112665e-01 9.36415136e-01\n",
      " 9.98331249e-01 9.95941460e-01 9.85988319e-01 9.95539367e-01\n",
      " 9.98299778e-01 9.98736322e-01 9.99351919e-01 7.73294449e-01\n",
      " 9.16027129e-01 9.98010933e-01 9.95834708e-01 9.69905198e-01\n",
      " 2.03309715e-01 9.42384064e-01 9.39822674e-01 1.69045821e-01\n",
      " 7.27252662e-01 9.89549160e-01 6.68400168e-01 9.70450461e-01\n",
      " 5.24126808e-04 9.69130337e-01 9.80759084e-01 9.97165740e-01\n",
      " 1.32868588e-01 9.98419881e-01 5.73025867e-02 4.28787738e-01\n",
      " 6.65788725e-03 4.89854544e-01 9.73026574e-01 9.44411159e-02\n",
      " 4.40998040e-02 1.51604370e-04 9.84686553e-01 6.49680793e-01\n",
      " 9.93627787e-01 9.53388393e-01 2.88613319e-01 1.70458898e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 7 [0/43 (0%)]\tTrain Loss: 0.002927\n",
      "Train Epoch: 7 [10/43 (23%)]\tTrain Loss: 0.006790\n",
      "Train Epoch: 7 [20/43 (47%)]\tTrain Loss: 0.078698\n",
      "Train Epoch: 7 [30/43 (70%)]\tTrain Loss: 0.015041\n",
      "Train Epoch: 7 [40/43 (93%)]\tTrain Loss: 0.041444\n",
      "\n",
      "Train set: Average loss: 0.0000, Accuracy: 400/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.65654705e-06 5.33400953e-01 1.94744453e-01 5.05453311e-02\n",
      " 4.36208893e-06 2.55245632e-05 8.76696587e-01 9.31938142e-02\n",
      " 4.35468464e-05 2.15355419e-02 8.46740976e-02 2.28723991e-04\n",
      " 2.62905300e-01 1.47891624e-05 3.95670895e-06 1.97056806e-07\n",
      " 6.16820762e-04 4.83898431e-01 5.30219637e-04 2.00142078e-02\n",
      " 3.30770621e-03 3.98825705e-02 6.69002620e-05 7.99996197e-01\n",
      " 2.41915323e-02 1.03408971e-03 9.78441536e-01 4.34085174e-04\n",
      " 3.37773294e-04 3.57480144e-06 1.64844049e-03 1.36311665e-01\n",
      " 2.91203521e-02 8.87810602e-05 7.28819519e-04 9.46551911e-04\n",
      " 9.58274250e-05 3.16687316e-01 2.84193847e-02 1.59538519e-02\n",
      " 4.32310291e-02 2.86145449e-01 4.57720697e-01 9.35080424e-02\n",
      " 9.08645570e-01 1.21567985e-02 1.02915309e-01 4.64783795e-03\n",
      " 9.35806930e-01 7.53996253e-01 9.77457881e-01 9.98384878e-03\n",
      " 8.55638087e-02 7.94274820e-06 9.55408275e-01 7.27814404e-06\n",
      " 9.19255555e-01 3.35165439e-03 4.21371281e-01 2.81135994e-03\n",
      " 9.99686003e-01 9.99597847e-01 9.99819577e-01 9.99355376e-01\n",
      " 1.46544963e-01 8.74751866e-01 1.79824054e-01 9.98041391e-01\n",
      " 9.93072808e-01 9.94276464e-01 1.82721928e-01 6.86706305e-01\n",
      " 8.94151092e-01 9.10144329e-01 6.19272530e-01 9.54293132e-01\n",
      " 9.96446192e-01 9.89505827e-01 9.59439158e-01 9.96977329e-01\n",
      " 9.98446882e-01 9.99055326e-01 9.99449790e-01 9.50666726e-01\n",
      " 8.89630616e-01 9.99049008e-01 9.95819211e-01 9.84647632e-01\n",
      " 2.65822202e-01 9.58794713e-01 9.63434935e-01 7.90622532e-01\n",
      " 8.70310783e-01 9.93242085e-01 9.24554944e-01 9.84833956e-01\n",
      " 9.49169137e-03 9.94553447e-01 9.91414487e-01 9.98746276e-01\n",
      " 4.18595195e-01 9.97700751e-01 9.19481516e-02 5.59406519e-01\n",
      " 4.88089025e-02 7.97698677e-01 9.91297126e-01 1.08934268e-01\n",
      " 1.93874955e-01 1.87594667e-02 9.88850534e-01 9.52441752e-01\n",
      " 9.97193635e-01 9.84241664e-01 1.55323848e-01 2.75261641e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 8 [0/43 (0%)]\tTrain Loss: 0.051527\n",
      "Train Epoch: 8 [10/43 (23%)]\tTrain Loss: 0.012240\n",
      "Train Epoch: 8 [20/43 (47%)]\tTrain Loss: 0.013421\n",
      "Train Epoch: 8 [30/43 (70%)]\tTrain Loss: 0.052140\n",
      "Train Epoch: 8 [40/43 (93%)]\tTrain Loss: 0.003860\n",
      "\n",
      "Train set: Average loss: 0.0007, Accuracy: 397/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.20104708e-07 5.87463558e-01 7.48671964e-02 1.53454430e-02\n",
      " 3.61603895e-07 8.73880799e-06 7.75001287e-01 2.63530519e-02\n",
      " 7.68950576e-06 4.07523997e-02 6.80156499e-02 2.24381263e-04\n",
      " 3.07325333e-01 7.29326057e-05 3.65436449e-06 7.54721654e-08\n",
      " 4.35950002e-04 3.40519160e-01 9.62473336e-04 2.47308146e-02\n",
      " 1.77793438e-03 4.06694859e-02 3.85132116e-05 7.15657830e-01\n",
      " 9.54675674e-03 2.41610967e-03 9.84909117e-01 2.57526466e-04\n",
      " 8.04999087e-04 1.45737351e-06 4.55978472e-04 6.46931157e-02\n",
      " 1.72169004e-02 4.93258849e-05 1.90143578e-03 9.93999885e-04\n",
      " 6.37247067e-05 2.17661560e-01 3.88928242e-02 3.68511453e-02\n",
      " 7.68224970e-02 4.49571699e-01 2.41141528e-01 2.74257325e-02\n",
      " 7.08259702e-01 3.31689231e-02 2.37359226e-01 5.85525110e-03\n",
      " 9.25682902e-01 6.63298965e-01 9.82384980e-01 6.48293237e-04\n",
      " 9.70472097e-02 1.13249757e-06 9.66728508e-01 8.42332497e-07\n",
      " 9.65525508e-01 1.10032631e-03 5.24686933e-01 7.27144827e-04\n",
      " 9.99798596e-01 9.99873757e-01 9.99868512e-01 9.99684691e-01\n",
      " 6.90758675e-02 8.05232108e-01 5.49638122e-02 9.98578906e-01\n",
      " 9.79925156e-01 9.94002044e-01 3.16911697e-01 7.35968828e-01\n",
      " 7.82759190e-01 8.15510690e-01 5.76911986e-01 9.57334161e-01\n",
      " 9.96937156e-01 9.95314479e-01 9.87736046e-01 9.96901989e-01\n",
      " 9.98678148e-01 9.99326348e-01 9.99489307e-01 9.55627084e-01\n",
      " 9.44212317e-01 9.99017954e-01 9.97790933e-01 9.80959117e-01\n",
      " 3.93283725e-01 9.84311998e-01 9.92300510e-01 3.35154235e-01\n",
      " 7.18841434e-01 9.93410647e-01 8.77069473e-01 9.85062599e-01\n",
      " 1.05147704e-03 9.93447602e-01 9.93576467e-01 9.99237537e-01\n",
      " 3.78666550e-01 9.98724163e-01 3.20872754e-01 5.67327499e-01\n",
      " 3.84059362e-02 8.31599712e-01 9.90916193e-01 6.83297366e-02\n",
      " 1.21814243e-01 9.61095840e-03 9.92050231e-01 9.77083862e-01\n",
      " 9.97384369e-01 9.89406288e-01 4.71088111e-01 3.51823270e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/43 (0%)]\tTrain Loss: 0.010700\n",
      "Train Epoch: 9 [10/43 (23%)]\tTrain Loss: 0.001076\n",
      "Train Epoch: 9 [20/43 (47%)]\tTrain Loss: 0.024540\n",
      "Train Epoch: 9 [30/43 (70%)]\tTrain Loss: 0.027152\n",
      "Train Epoch: 9 [40/43 (93%)]\tTrain Loss: 0.024049\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 395/424 (93%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.94721804e-06 8.32545280e-01 1.35125443e-01 2.53247190e-02\n",
      " 3.47989726e-06 1.95817174e-05 9.14246380e-01 6.81327507e-02\n",
      " 3.40221231e-05 4.45152968e-02 8.93172249e-02 1.06086285e-04\n",
      " 2.02603608e-01 3.25470173e-05 3.81569043e-06 1.79416446e-07\n",
      " 7.82749674e-04 4.80327994e-01 4.51838132e-04 1.87075734e-02\n",
      " 2.65796692e-03 2.92467233e-02 5.93354926e-05 8.76827180e-01\n",
      " 1.22928414e-02 1.24949159e-03 9.87924099e-01 4.08056396e-04\n",
      " 2.48040596e-04 2.68038639e-06 1.25500548e-03 7.77366757e-02\n",
      " 3.43780629e-02 2.07564590e-04 2.62203324e-03 1.64450193e-03\n",
      " 8.92404205e-05 3.44164371e-01 4.78124246e-02 4.33274694e-02\n",
      " 5.98677099e-02 5.10472000e-01 4.50375736e-01 8.44029486e-02\n",
      " 8.98211181e-01 2.24468280e-02 1.04449950e-01 1.97213213e-03\n",
      " 9.33961928e-01 7.06131399e-01 9.71004725e-01 3.77470511e-03\n",
      " 9.28704292e-02 5.67143934e-06 9.73583639e-01 3.87824048e-06\n",
      " 9.67359960e-01 4.71550366e-03 4.79501396e-01 1.43675681e-03\n",
      " 9.99827385e-01 9.99839306e-01 9.99869585e-01 9.99744117e-01\n",
      " 9.95992869e-02 9.01575267e-01 1.52825609e-01 9.98669267e-01\n",
      " 9.93734062e-01 9.96533751e-01 3.82607937e-01 8.78827572e-01\n",
      " 9.07269835e-01 9.14667547e-01 5.86561203e-01 9.67741966e-01\n",
      " 9.97824192e-01 9.95221913e-01 9.81999040e-01 9.97714520e-01\n",
      " 9.98786867e-01 9.99266803e-01 9.99511361e-01 9.63690639e-01\n",
      " 9.19005513e-01 9.99019265e-01 9.97773945e-01 9.87705112e-01\n",
      " 3.71158093e-01 9.81042504e-01 9.87116992e-01 6.38841271e-01\n",
      " 8.63377333e-01 9.95752096e-01 9.56627250e-01 9.90910232e-01\n",
      " 7.61664938e-03 9.96009827e-01 9.95321691e-01 9.99330997e-01\n",
      " 4.07310486e-01 9.98531461e-01 2.32315764e-01 5.89151919e-01\n",
      " 1.61297526e-02 7.61114120e-01 9.90487754e-01 1.53228149e-01\n",
      " 1.28192022e-01 2.99060382e-02 9.93293285e-01 9.67544854e-01\n",
      " 9.98469651e-01 9.90547240e-01 1.80637464e-01 4.66336310e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 10 [0/43 (0%)]\tTrain Loss: 0.028403\n",
      "Train Epoch: 10 [10/43 (23%)]\tTrain Loss: 0.030009\n",
      "Train Epoch: 10 [20/43 (47%)]\tTrain Loss: 0.005621\n",
      "Train Epoch: 10 [30/43 (70%)]\tTrain Loss: 0.088955\n",
      "Train Epoch: 10 [40/43 (93%)]\tTrain Loss: 0.016090\n",
      "\n",
      "Train set: Average loss: 0.0049, Accuracy: 403/424 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.43972153e-07 2.41837054e-01 2.65554842e-02 5.91541920e-03\n",
      " 2.30839319e-07 5.66486096e-06 6.10218048e-01 9.24613886e-03\n",
      " 1.24747123e-06 2.12610494e-02 4.70233336e-02 5.15297070e-05\n",
      " 3.28979641e-02 2.64790856e-06 5.25619498e-07 7.18746751e-09\n",
      " 2.39208148e-05 2.39601016e-01 2.02158553e-04 8.52850638e-03\n",
      " 6.71534741e-04 1.04191452e-02 1.17079899e-05 6.53871596e-01\n",
      " 8.81799124e-03 5.23297407e-04 9.72502351e-01 9.02897737e-05\n",
      " 1.06670777e-04 2.25546330e-07 1.73292967e-04 1.87919606e-02\n",
      " 1.28055448e-02 2.16847784e-05 1.87718833e-04 1.58389390e-04\n",
      " 6.30441082e-06 1.34330481e-01 1.19491909e-02 1.23223029e-02\n",
      " 2.80767381e-02 2.55160928e-01 1.77269757e-01 1.05671585e-02\n",
      " 5.98124623e-01 6.58099726e-03 5.65455183e-02 1.46004779e-03\n",
      " 8.50247800e-01 4.99184966e-01 9.62712705e-01 2.77830899e-04\n",
      " 3.86575274e-02 3.28487005e-07 9.32076275e-01 1.75868408e-07\n",
      " 9.35076237e-01 2.29641548e-04 3.65754664e-01 2.56950094e-04\n",
      " 9.99800265e-01 9.99856710e-01 9.99830961e-01 9.99575198e-01\n",
      " 3.33542973e-02 6.33149505e-01 2.45881677e-02 9.96842146e-01\n",
      " 9.71356452e-01 9.91529107e-01 1.93084270e-01 6.71271443e-01\n",
      " 6.81356788e-01 6.92362130e-01 3.20312560e-01 8.95943224e-01\n",
      " 9.93111491e-01 9.76773381e-01 9.21951294e-01 9.92067814e-01\n",
      " 9.97567654e-01 9.98514116e-01 9.99326110e-01 9.33274508e-01\n",
      " 9.18215275e-01 9.98816252e-01 9.96921420e-01 9.73453701e-01\n",
      " 5.88954836e-02 9.64231551e-01 9.66982186e-01 2.55966157e-01\n",
      " 7.61304200e-01 9.78866279e-01 7.61947811e-01 9.67893243e-01\n",
      " 4.07756335e-04 9.91855025e-01 9.94220257e-01 9.98812795e-01\n",
      " 2.34804824e-01 9.97498333e-01 1.23926163e-01 3.00161153e-01\n",
      " 8.06040969e-03 7.11872220e-01 9.88828838e-01 3.35679837e-02\n",
      " 9.75132063e-02 6.05449406e-03 9.83391404e-01 9.47880745e-01\n",
      " 9.97120261e-01 9.81453300e-01 4.23126519e-02 2.66022444e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 41 TN= 50 FN= 15 FP= 10\n",
      "TP+FP 51\n",
      "precision 0.803921568627451\n",
      "recall 0.7321428571428571\n",
      "F1 0.766355140186916\n",
      "acc 0.7844827586206896\n",
      "AUCp 0.7827380952380953\n",
      "AUC 0.8940476190476191\n",
      "\n",
      " The epoch is 10, average recall: 0.7321, average precision: 0.8039,average F1: 0.7664, average accuracy: 0.7845, average AUC: 0.8940\n",
      "Train Epoch: 11 [0/43 (0%)]\tTrain Loss: 0.007338\n",
      "Train Epoch: 11 [10/43 (23%)]\tTrain Loss: 0.010174\n",
      "Train Epoch: 11 [20/43 (47%)]\tTrain Loss: 0.026413\n",
      "Train Epoch: 11 [30/43 (70%)]\tTrain Loss: 0.001861\n",
      "Train Epoch: 11 [40/43 (93%)]\tTrain Loss: 0.001297\n",
      "\n",
      "Train set: Average loss: 0.0002, Accuracy: 396/424 (93%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.97392727e-06 8.67684603e-01 3.31356764e-01 2.57695392e-02\n",
      " 4.40004260e-06 6.81467645e-05 9.39215422e-01 1.75202280e-01\n",
      " 9.01836684e-05 1.36272423e-02 1.69851501e-02 8.99484221e-05\n",
      " 1.43687293e-01 3.90367670e-04 2.33240225e-05 5.95229551e-07\n",
      " 2.58290814e-03 3.43579113e-01 3.25281348e-04 1.75900795e-02\n",
      " 1.31789141e-03 5.48414141e-02 1.40037824e-04 8.56446981e-01\n",
      " 1.65328123e-02 2.23856955e-03 9.84138548e-01 1.72667101e-03\n",
      " 7.23001431e-04 7.18059619e-06 4.28590039e-03 2.53142953e-01\n",
      " 6.82642236e-02 7.54999754e-04 8.00741371e-03 5.33378636e-03\n",
      " 1.87921003e-04 4.06172633e-01 9.78395864e-02 8.92474353e-02\n",
      " 1.33300841e-01 6.34803355e-01 4.95231032e-01 1.09346308e-01\n",
      " 8.37862730e-01 2.88009979e-02 1.43148333e-01 4.41406574e-03\n",
      " 9.67330158e-01 7.75563002e-01 9.83687103e-01 2.06898502e-03\n",
      " 5.59505224e-02 7.44063436e-06 9.15913105e-01 2.07952826e-06\n",
      " 9.10418808e-01 1.33413833e-03 4.20316756e-01 1.56281213e-03\n",
      " 9.99829173e-01 9.99867201e-01 9.99895930e-01 9.99708116e-01\n",
      " 2.58876920e-01 9.84211862e-01 3.29056889e-01 9.99447644e-01\n",
      " 9.97352839e-01 9.97739077e-01 6.72113299e-01 9.31213200e-01\n",
      " 9.23811018e-01 9.79241967e-01 7.84511685e-01 9.68461275e-01\n",
      " 9.98812675e-01 9.96442616e-01 9.94703352e-01 9.98881519e-01\n",
      " 9.99306440e-01 9.99539495e-01 9.99698043e-01 9.54764783e-01\n",
      " 9.40667570e-01 9.99375880e-01 9.97221231e-01 9.89044070e-01\n",
      " 4.08978641e-01 9.86149073e-01 9.89490926e-01 7.06681132e-01\n",
      " 8.26372981e-01 9.95484471e-01 8.53827000e-01 9.86328006e-01\n",
      " 1.35727273e-03 9.96264160e-01 9.94889081e-01 9.99641538e-01\n",
      " 5.47609389e-01 9.99064624e-01 3.53401810e-01 6.09024465e-01\n",
      " 9.54771414e-03 7.01583683e-01 9.90471840e-01 1.42864868e-01\n",
      " 1.50262088e-01 9.53169167e-03 9.95897293e-01 9.79345679e-01\n",
      " 9.98417854e-01 9.89336252e-01 7.32884705e-01 6.25137269e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/43 (0%)]\tTrain Loss: 0.073252\n",
      "Train Epoch: 12 [10/43 (23%)]\tTrain Loss: 0.015270\n",
      "Train Epoch: 12 [20/43 (47%)]\tTrain Loss: 0.005173\n",
      "Train Epoch: 12 [30/43 (70%)]\tTrain Loss: 0.019806\n",
      "Train Epoch: 12 [40/43 (93%)]\tTrain Loss: 0.004938\n",
      "\n",
      "Train set: Average loss: 0.0003, Accuracy: 401/424 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.88456918e-07 6.87983871e-01 2.59953827e-01 1.23025766e-02\n",
      " 9.45885517e-07 5.19734476e-06 9.04018104e-01 6.42210096e-02\n",
      " 6.49969661e-06 6.89050881e-03 7.48499390e-03 3.92624534e-05\n",
      " 1.08494051e-02 1.38701042e-04 1.84212865e-06 1.58220217e-07\n",
      " 1.19333621e-03 3.67026538e-01 6.98793854e-04 7.10147293e-03\n",
      " 2.08331575e-03 4.71625328e-02 4.96776156e-05 8.02256644e-01\n",
      " 3.45401689e-02 2.96575075e-04 9.79348898e-01 1.96486275e-04\n",
      " 2.79799715e-05 1.82776546e-07 1.14258775e-03 1.93100974e-01\n",
      " 4.10625823e-02 3.28846872e-05 1.10840294e-04 1.42945748e-04\n",
      " 1.69302602e-05 4.73378032e-01 6.59214752e-03 4.43546660e-03\n",
      " 5.87523682e-03 1.36772275e-01 3.68595332e-01 1.12640314e-01\n",
      " 8.28960717e-01 1.13112910e-03 3.80030051e-02 9.04678134e-04\n",
      " 9.30238605e-01 6.35775030e-01 9.73889172e-01 5.14542963e-03\n",
      " 6.69822767e-02 7.20644584e-06 9.13421869e-01 6.56070233e-06\n",
      " 9.18313682e-01 7.78973277e-04 4.71547425e-01 9.27687273e-04\n",
      " 9.99856830e-01 9.99790490e-01 9.99898076e-01 9.99767482e-01\n",
      " 6.06158674e-02 9.21286881e-01 2.09600136e-01 9.98075485e-01\n",
      " 9.95809793e-01 9.92768764e-01 2.56325960e-01 8.19038749e-01\n",
      " 9.54751372e-01 9.16230321e-01 4.27825153e-01 9.51707006e-01\n",
      " 9.95943129e-01 9.79460061e-01 9.89682138e-01 9.99293447e-01\n",
      " 9.99352634e-01 9.99528170e-01 9.99682188e-01 9.80222642e-01\n",
      " 9.23707664e-01 9.99459445e-01 9.97196198e-01 9.89189625e-01\n",
      " 2.45869458e-01 9.74804401e-01 9.80519593e-01 7.33263254e-01\n",
      " 9.05524909e-01 9.92331386e-01 8.39638710e-01 9.86228228e-01\n",
      " 5.47739351e-03 9.97947991e-01 9.92361426e-01 9.99212027e-01\n",
      " 4.27754551e-01 9.98786271e-01 1.53280854e-01 2.05211744e-01\n",
      " 1.61231849e-02 8.33459079e-01 9.94086981e-01 5.51180355e-02\n",
      " 6.97133616e-02 3.53350653e-03 9.95170891e-01 9.71229136e-01\n",
      " 9.98980105e-01 9.83963907e-01 1.75236747e-01 3.98145705e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 13 [0/43 (0%)]\tTrain Loss: 0.081547\n",
      "Train Epoch: 13 [10/43 (23%)]\tTrain Loss: 0.002700\n",
      "Train Epoch: 13 [20/43 (47%)]\tTrain Loss: 0.009583\n",
      "Train Epoch: 13 [30/43 (70%)]\tTrain Loss: 0.022981\n",
      "Train Epoch: 13 [40/43 (93%)]\tTrain Loss: 0.006253\n",
      "\n",
      "Train set: Average loss: 0.0025, Accuracy: 400/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.37082097e-07 3.26539248e-01 2.12315898e-02 7.49031920e-03\n",
      " 5.94899277e-08 3.46706429e-06 3.06159526e-01 1.72769427e-02\n",
      " 1.49344351e-05 4.57157660e-03 3.28134783e-02 3.01101863e-05\n",
      " 7.95577560e-03 2.88174069e-05 5.66143001e-07 1.99983639e-08\n",
      " 6.23644955e-05 5.09777740e-02 5.30775615e-05 3.36468196e-03\n",
      " 6.69203757e-04 1.67678464e-02 6.46108401e-06 7.35111773e-01\n",
      " 1.58197142e-03 3.25535104e-04 9.82491434e-01 1.32079265e-04\n",
      " 2.46639092e-06 6.12849789e-08 9.12241958e-05 6.80894405e-03\n",
      " 3.89085826e-03 7.67612146e-05 3.27683883e-05 8.34638049e-05\n",
      " 2.15305226e-05 1.09687492e-01 3.22953775e-03 4.91760811e-03\n",
      " 1.79350260e-03 2.69167349e-02 1.90520659e-01 1.39211153e-03\n",
      " 4.41295415e-01 1.48212886e-03 1.06197685e-01 1.51973905e-03\n",
      " 9.12718952e-01 5.84081829e-01 9.79928136e-01 5.37558401e-04\n",
      " 7.98832178e-02 2.47116100e-06 1.02030329e-01 7.81810854e-07\n",
      " 8.16320479e-01 5.76951024e-05 6.71322346e-01 2.08084565e-03\n",
      " 9.99726117e-01 9.99865413e-01 9.99908566e-01 9.99859333e-01\n",
      " 4.52193394e-02 8.76177728e-01 1.68368928e-02 9.99431551e-01\n",
      " 9.87893522e-01 9.93206024e-01 6.55934401e-03 4.52358276e-03\n",
      " 7.66908586e-01 7.37381220e-01 4.76571284e-02 9.16895866e-01\n",
      " 9.89000320e-01 9.89864886e-01 9.75543857e-01 9.97041643e-01\n",
      " 9.98205662e-01 9.97287154e-01 9.99529958e-01 9.22120154e-01\n",
      " 9.34971690e-01 9.99330759e-01 9.91769552e-01 8.98150802e-01\n",
      " 1.29092326e-02 1.75574049e-01 5.95648587e-01 1.76078863e-02\n",
      " 5.23188889e-01 9.88941133e-01 1.26205370e-01 9.51075852e-01\n",
      " 3.95758892e-04 9.42702949e-01 9.83018816e-01 9.98322070e-01\n",
      " 2.32183307e-01 9.97874856e-01 2.00606836e-03 3.41642797e-02\n",
      " 1.39756216e-04 2.12664708e-01 9.88163173e-01 1.12591043e-01\n",
      " 1.51382834e-02 5.43791612e-05 9.81344819e-01 9.46802139e-01\n",
      " 9.99004662e-01 9.00149345e-01 6.89132197e-04 1.03507249e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 14 [0/43 (0%)]\tTrain Loss: 0.008079\n",
      "Train Epoch: 14 [10/43 (23%)]\tTrain Loss: 0.016823\n",
      "Train Epoch: 14 [20/43 (47%)]\tTrain Loss: 0.000647\n",
      "Train Epoch: 14 [30/43 (70%)]\tTrain Loss: 0.010439\n",
      "Train Epoch: 14 [40/43 (93%)]\tTrain Loss: 0.046585\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 410/424 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.65608049e-06 6.10248148e-01 3.38943712e-02 5.19142160e-03\n",
      " 4.60646959e-07 5.87525683e-05 4.19823915e-01 1.73337117e-03\n",
      " 5.53448153e-05 3.31562981e-02 2.33509839e-01 2.76817969e-04\n",
      " 2.16515228e-01 2.63090292e-03 1.70072803e-06 3.58065861e-08\n",
      " 2.43507908e-03 1.61613286e-01 1.00584701e-03 3.65188951e-03\n",
      " 5.26416115e-04 3.73134203e-02 8.41839847e-06 9.58778381e-01\n",
      " 2.67374981e-02 3.90063971e-03 9.96251047e-01 5.42406706e-05\n",
      " 1.41048571e-04 7.80397897e-08 4.35686263e-04 5.61329257e-03\n",
      " 1.41732290e-03 2.65382787e-05 1.25339546e-04 6.56254633e-05\n",
      " 1.33312555e-04 1.34164825e-01 4.50927485e-03 1.08451070e-02\n",
      " 2.70469952e-02 1.14207752e-01 2.26584598e-02 2.99109728e-04\n",
      " 5.16547203e-01 1.15281716e-02 2.27531437e-02 2.22135102e-04\n",
      " 9.57898259e-01 9.34450328e-01 9.90543664e-01 7.78489120e-05\n",
      " 2.29778916e-01 3.71878286e-06 8.15156758e-01 9.04219235e-07\n",
      " 9.47784483e-01 2.61667359e-04 8.76811504e-01 1.14799528e-04\n",
      " 9.99971151e-01 9.99979615e-01 9.99983430e-01 9.99968529e-01\n",
      " 1.64985936e-02 8.27267408e-01 2.96337549e-02 9.99636531e-01\n",
      " 9.55752611e-01 9.97913301e-01 2.58979708e-01 6.87684357e-01\n",
      " 9.27349389e-01 9.25623953e-01 5.09633839e-01 9.85026419e-01\n",
      " 9.98472512e-01 9.96498704e-01 9.92391169e-01 9.93636250e-01\n",
      " 9.99185860e-01 9.99685168e-01 9.99812305e-01 9.94314373e-01\n",
      " 9.86044049e-01 9.99802530e-01 9.99260485e-01 9.53143358e-01\n",
      " 6.53200269e-01 9.74936843e-01 9.95798767e-01 9.42425337e-03\n",
      " 4.93625849e-01 9.98764634e-01 8.50672483e-01 9.91306722e-01\n",
      " 6.42131781e-03 9.86478746e-01 9.97841716e-01 9.99771416e-01\n",
      " 2.65928358e-01 9.99614477e-01 4.13384885e-02 6.06595688e-02\n",
      " 5.23679599e-04 7.71461725e-01 9.94540036e-01 1.04872920e-01\n",
      " 3.40792201e-02 5.69733744e-03 9.97732997e-01 9.56462026e-01\n",
      " 9.99443710e-01 9.88837242e-01 1.28545286e-02 2.84065725e-03]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [0/43 (0%)]\tTrain Loss: 0.003931\n",
      "Train Epoch: 15 [10/43 (23%)]\tTrain Loss: 0.002626\n",
      "Train Epoch: 15 [20/43 (47%)]\tTrain Loss: 0.002787\n",
      "Train Epoch: 15 [30/43 (70%)]\tTrain Loss: 0.009223\n",
      "Train Epoch: 15 [40/43 (93%)]\tTrain Loss: 0.042944\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 404/424 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.44320833e-05 3.48234147e-01 1.04701310e-01 2.25338325e-01\n",
      " 1.20328377e-06 6.89788476e-06 3.61649305e-01 5.20443171e-02\n",
      " 4.75699235e-05 6.38178491e-04 8.27503332e-04 8.68750547e-08\n",
      " 3.71069014e-02 1.12024765e-03 8.55965554e-05 3.65971823e-06\n",
      " 5.60931256e-03 1.34814367e-01 1.10943278e-03 2.62030819e-03\n",
      " 2.10763607e-03 8.03449228e-02 2.64028349e-04 9.83858407e-01\n",
      " 1.18697239e-02 3.41549814e-02 9.89562571e-01 1.96549180e-03\n",
      " 3.47209908e-03 2.64136105e-07 2.35046470e-03 2.40502208e-01\n",
      " 9.83755453e-04 4.53005632e-05 2.33933650e-04 1.16671763e-04\n",
      " 4.00413905e-04 8.64729524e-01 1.03075363e-01 8.09403285e-02\n",
      " 2.67801192e-02 5.45008659e-01 4.15429264e-01 1.75496668e-01\n",
      " 9.70388174e-01 9.67717841e-02 2.08419040e-01 3.17410449e-04\n",
      " 9.85254526e-01 9.24057722e-01 9.92278695e-01 1.03285373e-03\n",
      " 2.48127524e-02 1.40014554e-05 9.95058298e-01 2.22482709e-06\n",
      " 8.42359722e-01 1.46324828e-01 7.87033737e-02 3.94679559e-03\n",
      " 9.99990463e-01 9.99988914e-01 9.99992847e-01 9.99962807e-01\n",
      " 8.36449265e-02 9.90191102e-01 7.02080905e-01 9.99933839e-01\n",
      " 9.97623146e-01 9.99155283e-01 9.94895875e-01 9.81880784e-01\n",
      " 9.90807474e-01 9.88113701e-01 9.07495499e-01 9.98200059e-01\n",
      " 9.75023389e-01 9.83716726e-01 9.99519110e-01 9.99937773e-01\n",
      " 9.99924421e-01 9.99926329e-01 9.99935389e-01 9.80422437e-01\n",
      " 9.45797682e-01 9.99938846e-01 9.99754846e-01 9.97361839e-01\n",
      " 5.41574538e-01 9.98083591e-01 9.97001827e-01 8.17560554e-01\n",
      " 9.80670571e-01 9.98083711e-01 7.57855296e-01 9.83355999e-01\n",
      " 1.06668826e-02 9.97998655e-01 9.99725044e-01 9.99917030e-01\n",
      " 5.79678118e-01 9.99187648e-01 8.41937065e-01 3.79654132e-02\n",
      " 1.58418989e-04 2.84368247e-01 9.90204453e-01 2.94911653e-01\n",
      " 1.11954480e-01 2.17427183e-02 9.97948825e-01 9.61802661e-01\n",
      " 9.99394655e-01 9.94625628e-01 1.80332754e-02 4.43579406e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 16 [0/43 (0%)]\tTrain Loss: 0.032813\n",
      "Train Epoch: 16 [10/43 (23%)]\tTrain Loss: 0.045222\n",
      "Train Epoch: 16 [20/43 (47%)]\tTrain Loss: 0.024396\n",
      "Train Epoch: 16 [30/43 (70%)]\tTrain Loss: 0.023576\n",
      "Train Epoch: 16 [40/43 (93%)]\tTrain Loss: 0.023515\n",
      "\n",
      "Train set: Average loss: 0.0046, Accuracy: 397/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.25441324e-05 9.01671886e-01 9.71250057e-01 1.89017765e-02\n",
      " 6.86953854e-08 1.67840662e-05 9.79582429e-01 5.00729494e-03\n",
      " 4.66313759e-05 1.97093585e-03 2.19937623e-01 7.28089503e-07\n",
      " 7.92369902e-01 1.04247313e-02 5.23789422e-05 2.37992163e-06\n",
      " 2.50002854e-02 9.70422208e-01 2.03240756e-03 1.59279779e-02\n",
      " 4.86559060e-04 2.38389000e-01 1.83583514e-04 9.93306696e-01\n",
      " 7.04019237e-03 1.01687750e-02 9.94400799e-01 4.35367785e-03\n",
      " 1.23923749e-03 1.10970653e-07 3.94595601e-02 3.32253687e-02\n",
      " 2.29702424e-03 6.54854521e-04 2.88360263e-03 7.62604759e-05\n",
      " 6.12742006e-05 9.63275433e-01 2.99747378e-01 5.76813743e-02\n",
      " 1.14047937e-02 8.13209116e-01 9.33105588e-01 6.18357807e-02\n",
      " 9.91555274e-01 3.91125917e-01 2.66063679e-02 2.35997621e-04\n",
      " 9.93421137e-01 9.88970518e-01 9.95229840e-01 8.10050638e-04\n",
      " 5.94635420e-02 4.67215541e-05 5.63587964e-01 6.33152513e-06\n",
      " 9.82035160e-01 6.54573813e-02 5.97871423e-01 5.59498705e-02\n",
      " 9.99998093e-01 9.99997497e-01 9.99998450e-01 9.99995589e-01\n",
      " 4.52261306e-02 9.99698520e-01 8.30049813e-01 9.99848723e-01\n",
      " 9.98962760e-01 9.99234200e-01 9.94113624e-01 9.96553063e-01\n",
      " 9.37558532e-01 9.96469617e-01 9.10281479e-01 9.97689724e-01\n",
      " 9.99917150e-01 9.99739945e-01 9.99462783e-01 9.99681592e-01\n",
      " 9.97115731e-01 9.99739587e-01 9.99987006e-01 9.99738753e-01\n",
      " 9.98478115e-01 9.99971032e-01 9.99874234e-01 9.96194601e-01\n",
      " 5.27076900e-01 9.91983712e-01 9.98568892e-01 5.96153796e-01\n",
      " 6.55679166e-01 9.99446452e-01 5.56387186e-01 9.68580484e-01\n",
      " 3.65012023e-03 9.96494830e-01 9.98947322e-01 9.99989629e-01\n",
      " 8.51602793e-01 9.99967694e-01 7.04671741e-01 7.05764949e-01\n",
      " 3.22835142e-04 9.71506953e-01 9.99172449e-01 6.68565631e-01\n",
      " 1.96879562e-02 1.34063708e-02 9.98889029e-01 8.43657851e-01\n",
      " 9.99684811e-01 9.80303288e-01 6.37614056e-02 4.37254608e-02]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 17 [0/43 (0%)]\tTrain Loss: 0.002369\n",
      "Train Epoch: 17 [10/43 (23%)]\tTrain Loss: 0.002580\n",
      "Train Epoch: 17 [20/43 (47%)]\tTrain Loss: 0.029878\n",
      "Train Epoch: 17 [30/43 (70%)]\tTrain Loss: 0.011658\n",
      "Train Epoch: 17 [40/43 (93%)]\tTrain Loss: 0.000628\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 402/424 (95%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.97706957e-06 4.32958652e-04 2.05354043e-03 2.36491859e-02\n",
      " 2.28532213e-06 6.39688835e-07 2.21470394e-03 4.04644385e-03\n",
      " 5.85848931e-04 2.42659109e-04 1.07485272e-01 3.96168929e-08\n",
      " 2.63061166e-01 3.26693356e-02 5.16643224e-04 8.23881685e-10\n",
      " 9.47880745e-02 5.10106921e-01 1.51099905e-03 2.81941649e-02\n",
      " 2.11195093e-05 5.41725866e-02 8.79273211e-05 9.89943981e-01\n",
      " 8.97280127e-03 3.92173603e-03 8.52382243e-01 3.50272916e-02\n",
      " 9.05474871e-02 9.20206844e-07 7.93854240e-03 1.87007487e-02\n",
      " 7.82707531e-04 1.08893481e-04 7.15580900e-05 3.27676332e-07\n",
      " 1.70370586e-05 9.27395225e-01 1.52607970e-02 1.49120642e-02\n",
      " 7.26142619e-03 1.59083053e-01 8.68513703e-01 1.36193866e-02\n",
      " 9.84654009e-01 1.27479248e-03 7.18780002e-03 5.41666805e-06\n",
      " 8.13224375e-01 9.25622225e-01 9.72563028e-01 8.69563723e-04\n",
      " 1.36876814e-02 2.10189664e-05 8.49828571e-02 2.14116790e-05\n",
      " 9.92178023e-01 1.44275650e-02 6.92131102e-01 6.89285481e-03\n",
      " 9.99996185e-01 9.99993920e-01 9.99996305e-01 9.99990821e-01\n",
      " 4.93933529e-01 9.96948659e-01 9.54793572e-01 9.99850750e-01\n",
      " 9.99140620e-01 9.96455669e-01 1.09865293e-01 3.57355624e-01\n",
      " 9.68325198e-01 9.96404648e-01 9.66741323e-01 9.09893274e-01\n",
      " 9.88256752e-01 9.84137595e-01 9.95179415e-01 9.99087095e-01\n",
      " 9.99077678e-01 9.98621941e-01 9.99953151e-01 9.90971804e-01\n",
      " 9.85089779e-01 9.99871969e-01 9.98300731e-01 8.87754977e-01\n",
      " 1.66042466e-02 4.45785001e-03 9.54605818e-01 4.63757515e-01\n",
      " 4.48604912e-01 9.99727786e-01 9.81765151e-01 9.54972029e-01\n",
      " 1.81641281e-02 9.68364775e-01 9.99006927e-01 9.99944925e-01\n",
      " 6.53204203e-01 9.99822199e-01 5.87043047e-01 2.25544646e-02\n",
      " 4.40070231e-04 9.30384099e-01 9.97042954e-01 9.27136421e-01\n",
      " 1.21521302e-01 4.78591159e-04 9.98403013e-01 9.94923770e-01\n",
      " 9.99978065e-01 9.99201000e-01 9.62969568e-03 3.16040032e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/43 (0%)]\tTrain Loss: 0.025688\n",
      "Train Epoch: 18 [10/43 (23%)]\tTrain Loss: 0.049345\n",
      "Train Epoch: 18 [20/43 (47%)]\tTrain Loss: 0.012424\n",
      "Train Epoch: 18 [30/43 (70%)]\tTrain Loss: 0.010303\n",
      "Train Epoch: 18 [40/43 (93%)]\tTrain Loss: 0.007077\n",
      "\n",
      "Train set: Average loss: 0.0007, Accuracy: 385/424 (91%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.82113971e-03 2.62453616e-01 1.35332812e-03 3.41813313e-03\n",
      " 8.35101309e-05 2.02381955e-07 7.66477548e-03 3.05840839e-03\n",
      " 2.19537265e-04 9.41571197e-04 4.28285748e-02 1.38424783e-08\n",
      " 2.99620139e-03 2.81950738e-03 1.65180815e-03 6.37073754e-06\n",
      " 4.97981399e-01 7.91499019e-02 1.11741365e-05 2.86549125e-02\n",
      " 1.18669472e-03 3.58791091e-03 6.26056353e-05 9.72782254e-01\n",
      " 1.65322851e-02 2.31946893e-02 9.98679698e-01 5.53079247e-01\n",
      " 1.15941314e-03 3.07887035e-06 4.22954150e-02 1.31567493e-02\n",
      " 4.40735146e-02 1.23940399e-02 1.19717540e-02 2.45623742e-05\n",
      " 2.63736467e-04 3.36717404e-02 2.71637384e-02 1.47069581e-02\n",
      " 1.52766670e-03 1.77951783e-01 1.70364201e-01 2.37145927e-04\n",
      " 5.24214268e-01 1.66973636e-01 3.82997274e-01 3.39603121e-03\n",
      " 9.93194699e-01 8.09562027e-01 9.98748779e-01 5.14113199e-05\n",
      " 4.66134446e-03 7.29708408e-04 1.21336296e-01 5.80405072e-07\n",
      " 9.96869504e-01 2.22585004e-04 2.47810349e-01 1.79393304e-04\n",
      " 9.99998093e-01 9.99993920e-01 9.99998569e-01 9.99997139e-01\n",
      " 9.83956635e-01 9.94260073e-01 8.62247288e-01 9.99848247e-01\n",
      " 9.93777871e-01 9.88937616e-01 8.12242031e-01 9.55623031e-01\n",
      " 9.97529447e-01 9.99867201e-01 9.95457292e-01 9.18290257e-01\n",
      " 9.99806941e-01 9.93059635e-01 9.99024510e-01 9.99976397e-01\n",
      " 9.99930859e-01 9.99949098e-01 9.99982238e-01 9.91566062e-01\n",
      " 9.82887566e-01 9.99981165e-01 9.98534799e-01 9.67874706e-01\n",
      " 5.98630309e-01 1.11461535e-01 9.94480133e-01 9.37278330e-01\n",
      " 2.09874839e-01 9.99285281e-01 9.85552847e-01 9.81634855e-01\n",
      " 3.24196699e-05 9.96049225e-01 9.96082902e-01 9.99955893e-01\n",
      " 3.24285418e-01 9.99964952e-01 6.02471590e-01 2.12109044e-01\n",
      " 1.73820707e-03 8.16672146e-01 9.94313240e-01 9.40496266e-01\n",
      " 3.48516077e-01 4.24000202e-03 9.54047322e-01 9.99262154e-01\n",
      " 9.99985576e-01 9.95988429e-01 9.69050527e-01 8.24339222e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Train Epoch: 19 [0/43 (0%)]\tTrain Loss: 0.000955\n",
      "Train Epoch: 19 [10/43 (23%)]\tTrain Loss: 0.001744\n",
      "Train Epoch: 19 [20/43 (47%)]\tTrain Loss: 0.000520\n",
      "Train Epoch: 19 [30/43 (70%)]\tTrain Loss: 0.001478\n",
      "Train Epoch: 19 [40/43 (93%)]\tTrain Loss: 0.034560\n",
      "\n",
      "Train set: Average loss: 0.0063, Accuracy: 400/424 (94%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.58001624e-06 1.63310751e-01 6.54808106e-03 1.74842635e-03\n",
      " 1.69786708e-05 8.56826503e-08 6.30002841e-02 2.18506699e-04\n",
      " 3.29705969e-08 3.84083600e-03 4.71911550e-01 1.11310192e-06\n",
      " 5.10069402e-03 3.48417018e-07 5.78757908e-06 7.29108940e-10\n",
      " 4.98865347e-07 4.96168509e-02 7.67502794e-03 1.55984806e-02\n",
      " 5.21665315e-05 1.47919258e-04 5.38117533e-08 6.11821972e-02\n",
      " 6.97807525e-04 2.59930243e-06 5.65317310e-02 3.44199034e-05\n",
      " 7.03608123e-08 1.00016610e-11 1.39249733e-03 5.53144189e-03\n",
      " 7.01746112e-03 4.95614216e-08 8.27286968e-08 1.12892415e-08\n",
      " 1.06044924e-08 8.28666799e-03 3.36387195e-02 1.39282531e-06\n",
      " 4.16219373e-05 5.13494189e-04 1.01425638e-03 4.35386681e-07\n",
      " 9.15317476e-01 6.58947647e-01 1.66435063e-01 5.21759910e-04\n",
      " 9.28995907e-01 9.04033780e-01 9.86631691e-01 6.06639514e-05\n",
      " 3.77709768e-03 3.53612035e-04 7.09448934e-01 1.60584405e-05\n",
      " 9.96533036e-01 1.89680071e-03 4.11626026e-02 4.10083972e-04\n",
      " 9.99997377e-01 9.99995232e-01 9.99996066e-01 9.99993086e-01\n",
      " 1.34305097e-02 1.55229969e-02 3.54047000e-01 9.98681486e-01\n",
      " 9.85251904e-01 9.95691121e-01 9.94613349e-01 9.90571737e-01\n",
      " 9.58591461e-01 9.56998110e-01 7.14274347e-01 9.82201159e-01\n",
      " 9.99976397e-01 9.99900341e-01 9.98359978e-01 9.95313525e-01\n",
      " 9.99767005e-01 9.99968171e-01 9.99517560e-01 9.75869238e-01\n",
      " 9.72695112e-01 9.99883175e-01 9.99858856e-01 9.82856810e-01\n",
      " 4.52144071e-04 3.51623865e-03 8.96300554e-01 5.72509885e-01\n",
      " 4.45795268e-01 9.96497333e-01 9.84620690e-01 9.85051632e-01\n",
      " 2.81161250e-04 9.97004926e-01 9.97921407e-01 9.58296895e-01\n",
      " 8.97348002e-02 9.99290347e-01 4.12335247e-01 2.49474227e-01\n",
      " 4.43690181e-01 9.83413637e-01 9.94678378e-01 8.87129158e-02\n",
      " 8.92333508e-01 3.18487454e-03 9.94209647e-01 9.94409263e-01\n",
      " 9.99901295e-01 9.90979731e-01 2.84103137e-02 5.80240216e-04]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 20 [0/43 (0%)]\tTrain Loss: 0.008401\n",
      "Train Epoch: 20 [10/43 (23%)]\tTrain Loss: 0.011578\n",
      "Train Epoch: 20 [20/43 (47%)]\tTrain Loss: 0.136138\n",
      "Train Epoch: 20 [30/43 (70%)]\tTrain Loss: 0.005716\n",
      "Train Epoch: 20 [40/43 (93%)]\tTrain Loss: 0.007123\n",
      "\n",
      "Train set: Average loss: 0.0000, Accuracy: 410/424 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.36042148e-07 1.50679210e-02 7.69896852e-03 1.22499443e-03\n",
      " 2.68380020e-08 1.19997651e-06 6.16479840e-04 1.66700850e-03\n",
      " 1.65858728e-06 6.58141380e-06 2.45433627e-03 7.51004647e-10\n",
      " 4.22842242e-03 4.07309562e-05 1.50554624e-04 2.06178949e-10\n",
      " 6.20560797e-07 1.05728112e-01 4.26564948e-05 6.44807843e-03\n",
      " 2.31305694e-06 6.82406942e-04 1.08862332e-06 8.96476805e-01\n",
      " 1.35169097e-03 1.34216252e-05 5.25218070e-01 7.82724528e-05\n",
      " 1.19315620e-04 1.40105583e-09 7.27957115e-03 1.07426979e-01\n",
      " 2.72620451e-02 2.85614419e-06 1.65588642e-06 9.09430639e-07\n",
      " 1.68535498e-05 9.66244042e-01 9.68141615e-01 1.26866596e-02\n",
      " 1.39699690e-02 3.62170339e-02 6.33912265e-01 3.01341396e-02\n",
      " 9.88580406e-01 2.42622979e-02 1.60516484e-03 5.89193223e-05\n",
      " 8.93931329e-01 8.35444093e-01 9.71317887e-01 4.60934871e-06\n",
      " 1.92595340e-04 2.05414512e-08 5.13767183e-04 1.25182786e-09\n",
      " 9.56412852e-01 5.96245329e-08 3.55910248e-04 2.57460442e-06\n",
      " 9.99992847e-01 9.99998331e-01 9.99998689e-01 9.99998212e-01\n",
      " 7.73394406e-01 9.47851300e-01 6.66844010e-01 9.99986887e-01\n",
      " 9.98184741e-01 9.99170899e-01 8.97180796e-01 9.41037536e-01\n",
      " 7.59555459e-01 9.97824907e-01 7.70140886e-01 9.96080101e-01\n",
      " 9.46159005e-01 9.01714742e-01 9.53849971e-01 9.99898314e-01\n",
      " 9.99506354e-01 9.99927521e-01 9.99739230e-01 9.01119113e-01\n",
      " 6.92571640e-01 9.99910712e-01 9.99352276e-01 9.60619867e-01\n",
      " 5.12484519e-04 1.80406049e-02 1.28529683e-01 8.15898851e-02\n",
      " 4.54878807e-01 9.84111428e-01 2.79758841e-01 6.31483257e-01\n",
      " 1.16397650e-05 9.98072982e-01 9.95389223e-01 9.99954820e-01\n",
      " 5.94853222e-01 9.99989033e-01 9.03895915e-01 6.60360679e-02\n",
      " 1.57014672e-02 2.19241500e-01 9.85508978e-01 3.30318630e-01\n",
      " 2.67972611e-03 6.31322594e-09 9.99547064e-01 9.53360140e-01\n",
      " 9.99534011e-01 9.92550731e-01 1.59424275e-01 2.05406882e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 41 TN= 52 FN= 15 FP= 8\n",
      "TP+FP 49\n",
      "precision 0.8367346938775511\n",
      "recall 0.7321428571428571\n",
      "F1 0.7809523809523811\n",
      "acc 0.8017241379310345\n",
      "AUCp 0.799404761904762\n",
      "AUC 0.9068452380952381\n",
      "\n",
      " The epoch is 20, average recall: 0.7321, average precision: 0.8367,average F1: 0.7810, average accuracy: 0.8017, average AUC: 0.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [0/43 (0%)]\tTrain Loss: 0.010554\n",
      "Train Epoch: 21 [10/43 (23%)]\tTrain Loss: 0.000343\n",
      "Train Epoch: 21 [20/43 (47%)]\tTrain Loss: 0.000379\n",
      "Train Epoch: 21 [30/43 (70%)]\tTrain Loss: 0.001914\n",
      "Train Epoch: 21 [40/43 (93%)]\tTrain Loss: 0.013995\n",
      "\n",
      "Train set: Average loss: 0.0004, Accuracy: 407/424 (96%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.79323727e-07 1.76329445e-02 2.23679338e-02 1.11238216e-03\n",
      " 2.61968580e-08 1.21395267e-08 2.19586268e-02 3.49971349e-04\n",
      " 5.32380113e-08 9.47244928e-07 7.40417419e-03 8.97256047e-09\n",
      " 3.55889834e-03 4.10050925e-05 4.02508653e-04 4.42155229e-10\n",
      " 9.48808236e-07 1.24462716e-01 4.65264253e-04 1.35508537e-01\n",
      " 7.26460130e-05 6.40573259e-03 5.14023611e-07 7.84711778e-01\n",
      " 2.07175873e-02 2.12589162e-04 3.15721363e-01 9.90920284e-07\n",
      " 2.22528882e-07 1.85695868e-08 7.28154409e-05 4.17968661e-01\n",
      " 8.39645043e-03 1.70802850e-05 3.45731337e-07 2.50547919e-06\n",
      " 2.03510258e-08 4.15646821e-01 1.21558063e-01 4.53623477e-03\n",
      " 2.39126937e-04 3.63622676e-03 1.21703930e-01 2.27433676e-03\n",
      " 9.95258629e-01 1.55982310e-02 3.17706242e-02 3.79772478e-04\n",
      " 9.59008038e-01 6.83194846e-02 9.95758951e-01 2.41483402e-04\n",
      " 9.05081251e-05 1.71720194e-06 1.19960758e-04 8.44848014e-09\n",
      " 9.95892167e-01 7.10730852e-09 1.46581035e-04 1.33641006e-05\n",
      " 9.99996543e-01 9.99998808e-01 9.99999404e-01 9.99999285e-01\n",
      " 6.25753343e-01 9.62176323e-01 8.82501304e-01 9.98093784e-01\n",
      " 9.96920705e-01 9.99815047e-01 9.69475210e-01 9.95022058e-01\n",
      " 8.20585847e-01 9.81198549e-01 4.10594702e-01 9.78723884e-01\n",
      " 9.99947548e-01 9.99347270e-01 9.97062862e-01 9.99648094e-01\n",
      " 9.98952031e-01 9.99973059e-01 9.99890685e-01 9.99311805e-01\n",
      " 9.88502264e-01 9.99921083e-01 9.88473594e-01 5.72525144e-01\n",
      " 1.37481617e-03 8.33677419e-04 6.32052541e-01 2.76164830e-01\n",
      " 6.32466674e-01 9.99888062e-01 9.37865019e-01 9.66675162e-01\n",
      " 2.86605318e-05 9.99539971e-01 9.93641436e-01 9.99782503e-01\n",
      " 9.32592928e-01 9.99992251e-01 3.97578418e-01 9.77392137e-01\n",
      " 4.57762480e-01 9.94115710e-01 9.97485161e-01 1.33033106e-02\n",
      " 3.84369418e-02 1.12185353e-06 9.99651194e-01 9.96215045e-01\n",
      " 9.99927759e-01 9.98016715e-01 4.67721879e-01 1.32949259e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 22 [0/43 (0%)]\tTrain Loss: 0.018323\n",
      "Train Epoch: 22 [10/43 (23%)]\tTrain Loss: 0.015407\n",
      "Train Epoch: 22 [20/43 (47%)]\tTrain Loss: 0.000938\n",
      "Train Epoch: 22 [30/43 (70%)]\tTrain Loss: 0.033893\n",
      "Train Epoch: 22 [40/43 (93%)]\tTrain Loss: 0.001379\n",
      "\n",
      "Train set: Average loss: 0.0002, Accuracy: 412/424 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.27009152e-05 4.47444245e-03 1.51915357e-01 6.26080394e-01\n",
      " 1.87081478e-05 5.54745748e-06 1.29244374e-02 2.36964263e-02\n",
      " 9.92940739e-04 5.63954291e-06 2.91485097e-02 1.05997211e-08\n",
      " 8.85309875e-02 6.67317390e-01 5.98341107e-01 1.54516286e-07\n",
      " 9.58007108e-03 6.41277552e-01 5.77710762e-06 3.39506567e-01\n",
      " 2.77186646e-05 1.06225610e-02 7.54866551e-06 9.80419457e-01\n",
      " 2.75340229e-02 1.51630695e-04 8.93903852e-01 2.32773959e-06\n",
      " 4.72983316e-04 2.95487871e-06 2.07646644e-05 3.12889018e-03\n",
      " 2.29273777e-04 1.37169310e-03 1.01702490e-05 8.49403348e-03\n",
      " 6.04470588e-05 9.78727758e-01 9.90998626e-01 6.90597296e-01\n",
      " 2.57439941e-01 5.65402389e-01 9.49024856e-02 5.14625192e-01\n",
      " 9.97001827e-01 3.27955815e-03 5.41339932e-06 6.67646960e-09\n",
      " 8.19667280e-02 2.69487384e-04 7.11108387e-01 2.01123362e-06\n",
      " 5.95783675e-03 2.21682832e-08 2.57419684e-04 4.89296674e-08\n",
      " 9.96371508e-01 3.33476066e-07 3.60076781e-04 2.27607397e-05\n",
      " 9.99980807e-01 9.99999285e-01 9.99998808e-01 9.99997020e-01\n",
      " 8.87484670e-01 9.99968290e-01 9.99347985e-01 9.99797881e-01\n",
      " 9.99512672e-01 9.99375403e-01 5.20211995e-01 8.87090981e-01\n",
      " 6.33977592e-01 9.99804318e-01 9.07761037e-01 9.77045774e-01\n",
      " 9.97816086e-01 9.98995125e-01 9.99014616e-01 9.96961296e-01\n",
      " 9.74661887e-01 9.99770939e-01 9.97210085e-01 9.96984184e-01\n",
      " 9.72595274e-01 9.92823839e-01 9.19924438e-01 2.97489725e-02\n",
      " 8.11321557e-01 9.93805528e-01 4.77631867e-01 1.93649658e-03\n",
      " 9.43075240e-01 9.99982357e-01 7.12697387e-01 9.94319320e-01\n",
      " 3.85695930e-05 9.98764515e-01 9.99062955e-01 9.99998569e-01\n",
      " 9.95717108e-01 9.99993324e-01 9.92269516e-01 5.82231171e-02\n",
      " 1.11631889e-04 3.09456468e-01 6.14628971e-01 9.66343462e-01\n",
      " 7.14122579e-02 7.49488294e-09 9.99950767e-01 9.92965817e-01\n",
      " 9.99896049e-01 9.99908805e-01 9.19182241e-01 1.24561433e-02]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Train Epoch: 23 [0/43 (0%)]\tTrain Loss: 0.001099\n",
      "Train Epoch: 23 [10/43 (23%)]\tTrain Loss: 0.001485\n",
      "Train Epoch: 23 [20/43 (47%)]\tTrain Loss: 0.002854\n",
      "Train Epoch: 23 [30/43 (70%)]\tTrain Loss: 0.053562\n",
      "Train Epoch: 23 [40/43 (93%)]\tTrain Loss: 0.020066\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 412/424 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.30991982e-08 2.87013836e-06 2.46768559e-05 1.17993006e-03\n",
      " 1.69569802e-07 1.54766333e-08 1.77303673e-06 9.45821375e-05\n",
      " 1.86162069e-05 2.94579135e-04 3.20260506e-03 1.03461036e-06\n",
      " 6.70557492e-04 1.69613850e-05 6.03662602e-06 3.72448166e-12\n",
      " 2.33530528e-07 2.28891894e-02 2.13677225e-07 1.37000962e-03\n",
      " 1.65081715e-07 2.26007469e-05 6.78478045e-07 9.12516892e-01\n",
      " 9.47357621e-05 1.97622630e-05 9.83976960e-01 6.93167465e-07\n",
      " 2.55588866e-08 1.27461274e-13 1.71879528e-03 6.13765325e-03\n",
      " 1.87911501e-04 1.92132720e-05 1.14900081e-06 3.49179822e-06\n",
      " 2.12592226e-07 7.43041098e-01 5.55213690e-01 8.01614442e-06\n",
      " 4.72155898e-06 3.50703485e-02 8.76459759e-03 5.50087094e-02\n",
      " 9.97848034e-01 2.75315326e-02 1.81323430e-03 5.28060582e-06\n",
      " 9.71170306e-01 4.49563056e-01 9.98788178e-01 2.33283657e-07\n",
      " 1.27281179e-04 3.37465139e-10 3.61594021e-01 9.57162571e-10\n",
      " 9.99343097e-01 1.03889391e-07 1.05878385e-03 3.55383740e-08\n",
      " 9.99995828e-01 9.99999881e-01 9.99999762e-01 9.99999642e-01\n",
      " 2.44474504e-02 9.92626965e-01 9.62997556e-01 9.93878305e-01\n",
      " 9.98668313e-01 9.99947667e-01 9.73360658e-01 9.92246389e-01\n",
      " 9.91207182e-01 9.99849081e-01 7.02869117e-01 9.99253094e-01\n",
      " 9.83485818e-01 9.54654932e-01 9.84584093e-01 9.99783933e-01\n",
      " 9.99977946e-01 9.99997616e-01 9.99992967e-01 9.99312878e-01\n",
      " 9.22755420e-01 9.99995470e-01 9.99836564e-01 9.58107114e-01\n",
      " 1.06203565e-02 6.70822799e-01 8.36913407e-01 1.99957774e-03\n",
      " 3.17201585e-01 9.99988198e-01 9.63424206e-01 9.97250497e-01\n",
      " 4.43327044e-05 9.99925733e-01 9.99673009e-01 9.99997377e-01\n",
      " 8.63156497e-01 9.99999762e-01 8.18291068e-01 1.97688360e-02\n",
      " 6.65940315e-05 9.44574356e-01 9.95805264e-01 9.66355264e-01\n",
      " 1.61644705e-02 1.14123253e-07 9.99992728e-01 9.94497836e-01\n",
      " 9.99939322e-01 9.99956489e-01 3.91882390e-01 1.25410443e-04]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [0/43 (0%)]\tTrain Loss: 0.000411\n",
      "Train Epoch: 24 [10/43 (23%)]\tTrain Loss: 0.006735\n",
      "Train Epoch: 24 [20/43 (47%)]\tTrain Loss: 0.022878\n",
      "Train Epoch: 24 [30/43 (70%)]\tTrain Loss: 0.009693\n",
      "Train Epoch: 24 [40/43 (93%)]\tTrain Loss: 0.000555\n",
      "\n",
      "Train set: Average loss: 0.0036, Accuracy: 408/424 (96%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.49288608e-13 6.83397651e-02 1.92361046e-02 4.06563304e-05\n",
      " 2.76809118e-07 7.09947032e-11 2.22154204e-02 9.50847209e-07\n",
      " 5.34090816e-08 6.80257435e-05 3.60691249e-02 1.71231989e-08\n",
      " 2.72108155e-04 5.30340731e-06 2.50909688e-05 6.54292701e-13\n",
      " 2.58895398e-07 4.51175272e-02 1.38662401e-07 4.91218828e-03\n",
      " 7.96223844e-07 1.81874877e-03 2.00297527e-05 8.68692100e-01\n",
      " 2.13455465e-02 6.95305280e-05 7.60191381e-01 5.77452909e-07\n",
      " 4.35420056e-09 3.17750993e-14 3.90080786e-05 3.10407428e-04\n",
      " 6.71839825e-06 4.03410104e-06 8.90223006e-08 1.85584398e-07\n",
      " 2.62987604e-10 1.31673142e-01 3.43071406e-05 1.26702162e-06\n",
      " 2.08555292e-07 4.12232213e-04 3.84130071e-05 7.28844255e-02\n",
      " 9.20616508e-01 2.25157943e-04 4.12584450e-05 3.05313996e-08\n",
      " 7.49738216e-01 1.63904503e-02 9.99154925e-01 2.10436201e-06\n",
      " 3.26339941e-04 8.80777187e-11 8.00430402e-03 7.66676678e-09\n",
      " 9.86832619e-01 2.10650455e-06 6.81955018e-04 1.53715796e-08\n",
      " 9.99997377e-01 9.99999881e-01 9.99999523e-01 9.99999762e-01\n",
      " 5.22544933e-03 8.92797053e-01 6.75779760e-01 9.93238091e-01\n",
      " 9.97910202e-01 9.93819416e-01 2.49061927e-01 4.24204230e-01\n",
      " 5.54554939e-01 9.96362984e-01 2.02064645e-02 9.94111359e-01\n",
      " 9.99822199e-01 9.97845173e-01 9.99753654e-01 9.99566853e-01\n",
      " 9.99898434e-01 9.99968767e-01 9.99910712e-01 9.97706056e-01\n",
      " 8.45987558e-01 9.99945641e-01 9.99902487e-01 8.74172270e-01\n",
      " 2.57913452e-02 9.05013561e-01 8.89223754e-01 4.66834521e-03\n",
      " 8.28273669e-02 9.99920607e-01 9.45689499e-01 9.98993456e-01\n",
      " 2.02886527e-04 9.99748051e-01 9.97305036e-01 9.99998331e-01\n",
      " 6.24362826e-01 9.99998212e-01 2.58497834e-01 5.36856242e-05\n",
      " 1.01671458e-06 2.78648317e-01 9.36183929e-01 2.97045857e-01\n",
      " 2.48270422e-01 1.69718817e-07 9.99924302e-01 9.97953415e-01\n",
      " 9.99808252e-01 9.99885082e-01 1.13334902e-01 2.39788042e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 25 [0/43 (0%)]\tTrain Loss: 0.012117\n",
      "Train Epoch: 25 [10/43 (23%)]\tTrain Loss: 0.001041\n",
      "Train Epoch: 25 [20/43 (47%)]\tTrain Loss: 0.000476\n",
      "Train Epoch: 25 [30/43 (70%)]\tTrain Loss: 0.000613\n",
      "Train Epoch: 25 [40/43 (93%)]\tTrain Loss: 0.009173\n",
      "\n",
      "Train set: Average loss: 0.0002, Accuracy: 418/424 (99%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.26196514e-10 3.39491777e-02 2.03821855e-03 2.59674678e-04\n",
      " 6.04484285e-07 3.94048083e-09 4.91993502e-03 1.61227199e-05\n",
      " 3.10163159e-05 1.28201806e-04 1.91389062e-02 2.77981496e-08\n",
      " 6.07038855e-05 1.07719470e-03 1.42658723e-03 6.31107944e-10\n",
      " 3.93326714e-04 4.06538188e-01 1.16029879e-08 2.93892296e-03\n",
      " 4.26202951e-06 1.09630125e-03 2.05394936e-05 9.47223783e-01\n",
      " 1.13467006e-02 7.91940023e-04 9.73625600e-01 1.06268126e-04\n",
      " 1.94152008e-07 2.00406809e-11 4.27660561e-04 5.84650692e-03\n",
      " 4.79957380e-05 1.25730028e-02 6.63616345e-04 1.05281790e-04\n",
      " 1.39293957e-06 5.40654063e-01 9.25161317e-02 1.35394954e-03\n",
      " 1.12342741e-03 6.91819310e-01 4.39786538e-03 1.81884542e-01\n",
      " 9.90330577e-01 5.89229502e-02 4.17967472e-04 1.14887371e-06\n",
      " 9.09836233e-01 3.46050821e-02 9.99493480e-01 7.69806775e-07\n",
      " 5.92845841e-04 2.51772625e-09 3.17879654e-02 1.04584952e-09\n",
      " 9.96329129e-01 4.44641671e-07 5.42927580e-03 2.94660563e-08\n",
      " 9.99998331e-01 9.99999762e-01 9.99999642e-01 9.99999762e-01\n",
      " 5.64522184e-02 9.93793845e-01 9.65256810e-01 9.99180973e-01\n",
      " 9.99567926e-01 9.99970794e-01 7.99371004e-01 9.56149042e-01\n",
      " 9.84103322e-01 9.99921560e-01 6.60466135e-01 9.93981183e-01\n",
      " 9.98941362e-01 9.83123422e-01 9.99940395e-01 9.99911427e-01\n",
      " 9.99985933e-01 9.99998689e-01 9.99997973e-01 9.95725155e-01\n",
      " 9.40209866e-01 9.99995470e-01 9.99931335e-01 9.75152493e-01\n",
      " 6.24255121e-01 9.61359084e-01 9.94533777e-01 4.45364602e-02\n",
      " 3.21954697e-01 9.99956608e-01 9.52865660e-01 9.98241425e-01\n",
      " 7.18600813e-06 9.99928832e-01 9.99026775e-01 9.99999881e-01\n",
      " 8.38348150e-01 9.99999762e-01 9.75419760e-01 7.90657010e-04\n",
      " 2.75532657e-05 9.17744040e-01 9.98374701e-01 9.85517442e-01\n",
      " 1.95139796e-01 3.87119854e-07 9.99990940e-01 9.99945283e-01\n",
      " 9.99961853e-01 9.99981642e-01 9.46444809e-01 3.98303159e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Train Epoch: 26 [0/43 (0%)]\tTrain Loss: 0.005086\n",
      "Train Epoch: 26 [10/43 (23%)]\tTrain Loss: 0.000548\n",
      "Train Epoch: 26 [20/43 (47%)]\tTrain Loss: 0.008542\n",
      "Train Epoch: 26 [30/43 (70%)]\tTrain Loss: 0.000298\n",
      "Train Epoch: 26 [40/43 (93%)]\tTrain Loss: 0.017754\n",
      "\n",
      "Train set: Average loss: 0.0007, Accuracy: 412/424 (97%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.92434471e-10 3.14629497e-03 1.41991157e-04 5.48351731e-04\n",
      " 1.38723493e-07 1.05282660e-09 2.03456334e-03 2.50172816e-05\n",
      " 9.88738975e-06 4.53013141e-04 3.12114060e-02 7.90929420e-08\n",
      " 2.09995382e-03 4.71794792e-03 4.30773871e-05 4.17510557e-12\n",
      " 1.42036843e-05 5.60276955e-02 3.05663093e-07 4.50043287e-03\n",
      " 2.37838813e-05 2.04594014e-03 1.30818171e-05 9.89100516e-01\n",
      " 9.59784165e-03 7.39393581e-04 9.64339495e-01 2.46754207e-05\n",
      " 5.12354177e-08 4.36428801e-12 1.95224584e-05 3.06517381e-04\n",
      " 3.61419529e-06 2.88719009e-03 7.25382008e-04 5.36331208e-05\n",
      " 2.40139843e-06 6.42657280e-01 1.96222384e-02 6.76643394e-05\n",
      " 1.12247159e-04 1.90269530e-01 4.38847998e-03 3.97449918e-02\n",
      " 9.76998389e-01 5.00049479e-02 1.83118694e-03 3.24537439e-07\n",
      " 9.53156471e-01 2.88769752e-01 9.99361932e-01 2.99921737e-07\n",
      " 1.04034385e-02 1.12828646e-09 7.03598559e-01 1.36512779e-09\n",
      " 9.99059379e-01 3.23566292e-06 1.31203070e-01 2.50142506e-07\n",
      " 9.99998450e-01 1.00000000e+00 9.99999881e-01 9.99999881e-01\n",
      " 2.33429968e-01 9.94545579e-01 8.19266617e-01 9.99790490e-01\n",
      " 9.99066770e-01 9.99959707e-01 7.67036915e-01 9.85648274e-01\n",
      " 9.72694755e-01 9.99907374e-01 6.34118199e-01 9.94783342e-01\n",
      " 9.98398125e-01 9.97115731e-01 9.99738395e-01 9.98734891e-01\n",
      " 9.99914050e-01 9.99994397e-01 9.99997139e-01 9.79749024e-01\n",
      " 9.43543434e-01 9.99993324e-01 9.99930024e-01 9.85205829e-01\n",
      " 5.60080647e-01 7.99624145e-01 9.91000712e-01 4.43169475e-03\n",
      " 2.66713351e-01 9.99984384e-01 9.82476592e-01 9.97108757e-01\n",
      " 4.24994359e-05 9.99703586e-01 9.99070466e-01 9.99999881e-01\n",
      " 6.75975978e-01 9.99998331e-01 8.53735864e-01 1.66387457e-04\n",
      " 6.10479628e-06 8.75077248e-01 9.96342599e-01 9.95912373e-01\n",
      " 6.34712353e-02 1.64872927e-05 9.99995828e-01 9.99924779e-01\n",
      " 9.99990225e-01 9.99977827e-01 2.33700290e-01 5.62414643e-05]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [0/43 (0%)]\tTrain Loss: 0.000509\n",
      "Train Epoch: 27 [10/43 (23%)]\tTrain Loss: 0.105883\n",
      "Train Epoch: 27 [20/43 (47%)]\tTrain Loss: 0.000840\n",
      "Train Epoch: 27 [30/43 (70%)]\tTrain Loss: 0.000664\n",
      "Train Epoch: 27 [40/43 (93%)]\tTrain Loss: 0.000454\n",
      "\n",
      "Train set: Average loss: 0.0001, Accuracy: 414/424 (98%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.18373122e-11 7.93274585e-03 3.44226937e-05 2.03678486e-04\n",
      " 8.25742035e-08 5.53057378e-10 9.60201491e-04 7.29809790e-06\n",
      " 9.39796973e-06 4.20426310e-04 2.96188649e-02 2.27838974e-08\n",
      " 8.68113711e-04 5.49972523e-04 4.62058051e-06 3.43813832e-11\n",
      " 8.11113841e-06 5.77609278e-02 8.79088375e-08 1.93045940e-03\n",
      " 2.55099508e-06 4.55851550e-04 4.28735393e-06 9.57129896e-01\n",
      " 1.27878971e-03 4.11588233e-04 9.82202351e-01 2.44216026e-05\n",
      " 6.19043217e-09 1.86300714e-12 7.45683792e-05 9.50459391e-03\n",
      " 8.20601235e-06 1.46387581e-04 1.07428505e-05 3.96121686e-06\n",
      " 4.16222605e-07 6.96386456e-01 1.01541756e-02 2.36222604e-05\n",
      " 3.64931184e-05 1.69322416e-01 2.36784224e-03 9.07199830e-02\n",
      " 9.80720103e-01 8.59219134e-02 1.58083986e-03 6.81420806e-06\n",
      " 9.93043065e-01 2.35718086e-01 9.99949098e-01 1.64762730e-06\n",
      " 2.27093324e-03 4.91499896e-10 1.73049062e-01 1.09103926e-09\n",
      " 9.98167634e-01 6.18637841e-06 1.19340345e-02 3.66056874e-08\n",
      " 9.99998569e-01 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 8.98155123e-02 9.88123953e-01 8.95979762e-01 9.97848153e-01\n",
      " 9.98645365e-01 9.99953508e-01 7.27488160e-01 9.62320983e-01\n",
      " 9.76377070e-01 9.99930263e-01 6.81307554e-01 9.85101044e-01\n",
      " 9.99779761e-01 9.98045683e-01 9.99874115e-01 9.99787748e-01\n",
      " 9.99978900e-01 9.99996662e-01 9.99999166e-01 9.98167396e-01\n",
      " 9.79167223e-01 9.99997616e-01 9.99973536e-01 9.77587521e-01\n",
      " 1.11188754e-01 7.64217794e-01 9.92633760e-01 3.93316410e-02\n",
      " 2.23737523e-01 9.99968052e-01 9.32830632e-01 9.95098650e-01\n",
      " 2.85318965e-05 9.99829054e-01 9.95798171e-01 9.99999642e-01\n",
      " 7.32053280e-01 9.99999642e-01 7.01197147e-01 4.07658430e-04\n",
      " 1.06929901e-05 9.79734361e-01 9.97404397e-01 9.80115891e-01\n",
      " 3.27244662e-02 1.62684398e-06 9.99994397e-01 9.99706328e-01\n",
      " 9.99960303e-01 9.99938965e-01 1.96364447e-01 6.07819529e-04]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 28 [0/43 (0%)]\tTrain Loss: 0.000280\n",
      "Train Epoch: 28 [10/43 (23%)]\tTrain Loss: 0.011644\n",
      "Train Epoch: 28 [20/43 (47%)]\tTrain Loss: 0.000559\n",
      "Train Epoch: 28 [30/43 (70%)]\tTrain Loss: 0.000982\n",
      "Train Epoch: 28 [40/43 (93%)]\tTrain Loss: 0.000628\n",
      "\n",
      "Train set: Average loss: 0.0021, Accuracy: 419/424 (99%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.53510007e-10 1.12848235e-02 5.39758184e-04 4.00923978e-04\n",
      " 3.23217932e-07 1.26024158e-09 7.62330927e-03 2.64301798e-05\n",
      " 1.57837203e-05 1.12853094e-03 7.76800141e-02 1.16342058e-07\n",
      " 2.55357800e-03 2.22285371e-03 2.01625313e-04 1.71288012e-10\n",
      " 2.05163942e-05 5.93811333e-01 1.28055021e-07 6.88174320e-03\n",
      " 6.60303431e-06 1.33754173e-03 2.20378770e-05 9.88239288e-01\n",
      " 5.95029071e-03 1.39147916e-03 9.90388334e-01 6.63755563e-05\n",
      " 6.01039787e-08 2.25047238e-11 2.39754503e-04 2.39139274e-02\n",
      " 3.86281208e-05 3.17627704e-03 3.36623052e-04 6.09042763e-05\n",
      " 3.83421730e-06 8.60900819e-01 1.86916023e-01 3.33396631e-04\n",
      " 3.13162309e-04 6.59327865e-01 2.15622820e-02 3.53678852e-01\n",
      " 9.95448172e-01 3.78998548e-01 6.02892879e-03 6.42475197e-06\n",
      " 9.92287755e-01 5.89769483e-01 9.99783576e-01 7.87165277e-07\n",
      " 1.89221511e-03 7.07800263e-10 6.54136479e-01 3.15976023e-10\n",
      " 9.99163389e-01 2.70941723e-06 2.08825823e-02 1.93999075e-08\n",
      " 9.99998927e-01 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 1.44396663e-01 9.94342566e-01 9.07390654e-01 9.99663591e-01\n",
      " 9.99127209e-01 9.99984264e-01 9.59362507e-01 9.96427357e-01\n",
      " 9.92471695e-01 9.99965787e-01 9.25158262e-01 9.96754825e-01\n",
      " 9.99894142e-01 9.98304129e-01 9.99942422e-01 9.99835610e-01\n",
      " 9.99979377e-01 9.99996901e-01 9.99999046e-01 9.98156130e-01\n",
      " 9.77345347e-01 9.99997258e-01 9.99959469e-01 9.94323730e-01\n",
      " 1.45996407e-01 9.23297286e-01 9.94479179e-01 3.29882838e-02\n",
      " 4.00391728e-01 9.99970555e-01 9.39334750e-01 9.97185290e-01\n",
      " 4.76537316e-05 9.99869943e-01 9.98086572e-01 9.99999762e-01\n",
      " 8.40236127e-01 9.99999762e-01 9.36593473e-01 3.03397025e-03\n",
      " 5.80885026e-05 9.78294134e-01 9.98552978e-01 9.96767759e-01\n",
      " 7.40526915e-02 5.63082795e-05 9.99996305e-01 9.99827325e-01\n",
      " 9.99978065e-01 9.99980092e-01 7.27318466e-01 4.21407865e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Train Epoch: 29 [0/43 (0%)]\tTrain Loss: 0.000338\n",
      "Train Epoch: 29 [10/43 (23%)]\tTrain Loss: 0.000456\n",
      "Train Epoch: 29 [20/43 (47%)]\tTrain Loss: 0.000359\n",
      "Train Epoch: 29 [30/43 (70%)]\tTrain Loss: 0.001017\n",
      "Train Epoch: 29 [40/43 (93%)]\tTrain Loss: 0.000169\n",
      "\n",
      "Train set: Average loss: 0.0000, Accuracy: 421/424 (99%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.42062314e-11 1.88658666e-03 6.36491022e-05 2.46759766e-04\n",
      " 1.18667813e-07 7.12738257e-10 7.67984428e-04 5.87985778e-06\n",
      " 9.93216690e-06 2.81767745e-04 4.09165993e-02 2.47157459e-08\n",
      " 7.02473626e-04 7.10978929e-04 1.83515913e-05 6.35294872e-11\n",
      " 2.66592156e-06 2.62326807e-01 1.31620141e-07 1.55742862e-03\n",
      " 1.10184749e-06 7.71336199e-04 7.79802758e-06 9.90441799e-01\n",
      " 4.34817094e-03 2.53961887e-04 9.84592140e-01 2.77882773e-05\n",
      " 7.59098562e-09 1.77781943e-12 1.31436871e-04 5.98017126e-03\n",
      " 1.08818149e-05 2.64370372e-03 1.35430120e-04 2.00838858e-05\n",
      " 1.64940241e-06 7.56705165e-01 4.21971641e-02 5.60169246e-05\n",
      " 1.04007020e-04 3.99697721e-01 4.18414455e-03 1.93568379e-01\n",
      " 9.94170189e-01 9.04451907e-02 1.71044888e-03 1.92430662e-06\n",
      " 9.86876845e-01 3.17152232e-01 9.99770343e-01 5.45431419e-07\n",
      " 9.60306730e-04 3.37020023e-10 4.94918138e-01 3.65126984e-10\n",
      " 9.98613238e-01 6.40114467e-06 9.75924730e-03 5.52918422e-09\n",
      " 9.99998450e-01 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 8.94449279e-02 9.78767157e-01 8.86345327e-01 9.98490334e-01\n",
      " 9.98780072e-01 9.99969006e-01 8.67905617e-01 9.82545495e-01\n",
      " 9.86223817e-01 9.99925137e-01 6.61878765e-01 9.95023847e-01\n",
      " 9.99640822e-01 9.96625304e-01 9.99884129e-01 9.99779284e-01\n",
      " 9.99980569e-01 9.99995470e-01 9.99998689e-01 9.96573329e-01\n",
      " 9.69297647e-01 9.99994636e-01 9.99963760e-01 9.75132763e-01\n",
      " 1.42989337e-01 8.78017545e-01 9.91246641e-01 3.07180379e-02\n",
      " 3.18100333e-01 9.99963760e-01 9.15204227e-01 9.95939732e-01\n",
      " 3.59804726e-05 9.99723852e-01 9.98324335e-01 9.99999762e-01\n",
      " 8.32459033e-01 9.99999642e-01 8.68801951e-01 4.54399036e-04\n",
      " 8.55484268e-06 9.27996337e-01 9.96269703e-01 9.94976282e-01\n",
      " 6.44814894e-02 2.83453082e-05 9.99996066e-01 9.99678612e-01\n",
      " 9.99955416e-01 9.99971151e-01 3.43265533e-01 3.99112294e-04]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [0/43 (0%)]\tTrain Loss: 0.000698\n",
      "Train Epoch: 30 [10/43 (23%)]\tTrain Loss: 0.000206\n",
      "Train Epoch: 30 [20/43 (47%)]\tTrain Loss: 0.000354\n",
      "Train Epoch: 30 [30/43 (70%)]\tTrain Loss: 0.000178\n",
      "Train Epoch: 30 [40/43 (93%)]\tTrain Loss: 0.011901\n",
      "\n",
      "Train set: Average loss: 0.0013, Accuracy: 416/424 (98%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.85781025e-11 1.33679353e-03 8.88498253e-05 7.18651281e-05\n",
      " 1.67796479e-08 2.05400988e-10 4.18629817e-04 3.33034109e-06\n",
      " 1.02848833e-06 2.46915763e-04 4.10397314e-02 2.38103279e-08\n",
      " 5.46348492e-05 3.81215687e-05 1.06656153e-05 1.96912920e-11\n",
      " 1.50424985e-05 3.96139622e-01 2.06833768e-08 5.44110022e-04\n",
      " 1.21895553e-07 1.32967765e-03 2.45065144e-06 9.76832986e-01\n",
      " 1.15430914e-02 2.79194155e-05 9.82337475e-01 6.00725161e-06\n",
      " 3.84403259e-10 2.43515721e-14 3.10445794e-05 8.95804318e-04\n",
      " 6.28147427e-06 3.92161426e-04 7.71938085e-06 1.76814660e-06\n",
      " 4.73122306e-08 3.34184825e-01 1.58948861e-02 1.31457746e-05\n",
      " 4.11114379e-05 2.50220671e-02 2.78166175e-04 1.69509742e-02\n",
      " 9.58957493e-01 1.60734374e-02 2.72322271e-04 5.15768299e-08\n",
      " 9.35524404e-01 3.04010928e-01 9.99410868e-01 1.27693056e-07\n",
      " 3.43371998e-04 3.95996118e-11 1.59895718e-01 3.66778968e-11\n",
      " 9.99541759e-01 3.04939277e-07 1.36966957e-02 1.78351101e-09\n",
      " 9.99999166e-01 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 1.65279582e-02 9.66401637e-01 8.37863147e-01 9.97004211e-01\n",
      " 9.99364555e-01 9.99929786e-01 8.25748146e-01 9.32860494e-01\n",
      " 9.07938004e-01 9.99796450e-01 4.78025794e-01 9.81842935e-01\n",
      " 9.99776781e-01 9.94161785e-01 9.99443114e-01 9.99543607e-01\n",
      " 9.99976993e-01 9.99992251e-01 9.99997377e-01 9.97492313e-01\n",
      " 9.73277330e-01 9.99994755e-01 9.99932289e-01 9.07682002e-01\n",
      " 1.63216237e-02 8.19231212e-01 9.46859300e-01 1.15263253e-03\n",
      " 1.16005205e-01 9.99913096e-01 8.26806962e-01 9.90839660e-01\n",
      " 6.02778391e-06 9.99878407e-01 9.98408258e-01 9.99999762e-01\n",
      " 6.63477659e-01 9.99999762e-01 6.20933712e-01 2.53633043e-04\n",
      " 8.88821432e-06 9.86676931e-01 9.99428213e-01 9.81923282e-01\n",
      " 3.84543724e-02 1.65093513e-06 9.99996781e-01 9.99957800e-01\n",
      " 9.99981523e-01 9.99975681e-01 1.80118605e-01 1.94026111e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 53 FN= 11 FP= 7\n",
      "TP+FP 52\n",
      "precision 0.8653846153846154\n",
      "recall 0.8035714285714286\n",
      "F1 0.8333333333333334\n",
      "acc 0.8448275862068966\n",
      "AUCp 0.843452380952381\n",
      "AUC 0.9098214285714286\n",
      "\n",
      " The epoch is 30, average recall: 0.8036, average precision: 0.8654,average F1: 0.8333, average accuracy: 0.8448, average AUC: 0.9098\n",
      "Train Epoch: 31 [0/43 (0%)]\tTrain Loss: 0.000494\n",
      "Train Epoch: 31 [10/43 (23%)]\tTrain Loss: 0.000227\n",
      "Train Epoch: 31 [20/43 (47%)]\tTrain Loss: 0.000755\n",
      "Train Epoch: 31 [30/43 (70%)]\tTrain Loss: 0.000261\n",
      "Train Epoch: 31 [40/43 (93%)]\tTrain Loss: 0.000209\n",
      "\n",
      "Train set: Average loss: 0.0047, Accuracy: 417/424 (98%)\n",
      "\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.71077649e-11 1.81258877e-03 2.01961244e-04 1.93623364e-05\n",
      " 1.92027594e-09 2.57301402e-11 5.62295201e-04 3.98526345e-06\n",
      " 4.50231056e-07 1.80137285e-05 4.15276177e-03 5.23766275e-09\n",
      " 8.68072311e-06 2.33543851e-05 1.11239842e-05 3.25640426e-12\n",
      " 3.81615610e-06 1.07585467e-01 4.64436711e-09 1.57516869e-03\n",
      " 3.20528954e-07 3.95275914e-04 1.23839027e-06 8.60883772e-01\n",
      " 4.92236402e-04 3.25218571e-05 9.46549535e-01 1.70472595e-06\n",
      " 5.31758471e-10 1.37790568e-14 1.65227702e-05 4.07849642e-04\n",
      " 4.21621371e-06 1.37088346e-05 4.72505462e-07 1.08838812e-07\n",
      " 1.35891955e-08 1.16237849e-01 2.42358795e-03 2.64827486e-06\n",
      " 1.69527502e-05 1.73984263e-02 6.59284065e-04 1.15476502e-03\n",
      " 9.58599210e-01 5.15431445e-03 4.50568805e-05 5.26401536e-08\n",
      " 9.04284537e-01 5.95632941e-03 9.98686850e-01 1.04082725e-08\n",
      " 2.09948448e-05 1.52265505e-12 4.76192543e-03 4.92331610e-12\n",
      " 9.93923366e-01 2.90638358e-08 1.18347595e-03 2.62072752e-10\n",
      " 9.99997735e-01 9.99999762e-01 9.99999523e-01 9.99999523e-01\n",
      " 3.56849320e-02 8.60699475e-01 5.34075439e-01 9.95453238e-01\n",
      " 9.98177528e-01 9.99867678e-01 6.56297505e-01 7.81145632e-01\n",
      " 8.68681848e-01 9.99772608e-01 8.20300281e-01 9.68320072e-01\n",
      " 9.99624252e-01 9.85506058e-01 9.99536157e-01 9.99230027e-01\n",
      " 9.99949098e-01 9.99994040e-01 9.99997735e-01 9.41333652e-01\n",
      " 7.26296008e-01 9.99973416e-01 9.99764621e-01 8.77235949e-01\n",
      " 8.70032329e-03 4.28783447e-01 9.55841780e-01 1.14236458e-03\n",
      " 3.78850363e-02 9.99866843e-01 7.16030598e-01 9.80349183e-01\n",
      " 1.78616585e-06 9.99675989e-01 9.88581002e-01 9.99999285e-01\n",
      " 5.38684189e-01 9.99999642e-01 2.25680575e-01 8.21679831e-04\n",
      " 1.26640507e-05 9.64146316e-01 9.98228848e-01 9.36243832e-01\n",
      " 6.48233341e-03 1.85140276e-08 9.99987125e-01 9.99673605e-01\n",
      " 9.99952197e-01 9.99863863e-01 6.55886158e-02 4.30313958e-04]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "Train Epoch: 32 [0/43 (0%)]\tTrain Loss: 0.000208\n",
      "Train Epoch: 32 [10/43 (23%)]\tTrain Loss: 0.000652\n",
      "Train Epoch: 32 [20/43 (47%)]\tTrain Loss: 0.007823\n",
      "Train Epoch: 32 [30/43 (70%)]\tTrain Loss: 0.000417\n",
      "Train Epoch: 32 [40/43 (93%)]\tTrain Loss: 0.000183\n",
      "\n",
      "Train set: Average loss: 0.0002, Accuracy: 414/424 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "\n",
    "    scheduler.step()\n",
    "    model.drop_path_prob = args.drop_path_prob * epoch / args.epochs\n",
    "    train_acc, train_obj = train(train_loader, model, criterion_smooth, optimizer)\n",
    "    targetlist, scorelist, predlist = infer(val_loader, model, criterion_smooth,epoch)\n",
    "    \n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"model_backup/{}.pt\".format(modelname))  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "        f.close()     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
